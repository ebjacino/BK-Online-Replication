First we load in the packages
```{r}
library(tidyverse)
library(ggplot2)
library(lme4)
library(ggpubr)
library(forcats)
library(emmeans)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)
library("writexl")
library("xlsx")
library(viridis)
library(ppcor) #for partial correlation
library(lpSolve)
library(irr) #for inter-rater reliability

```
#Colors
```{r}
angular_color = "#E01A4F"
curved_color = "#FFC05C"
third_color = "#80B8EF"
congruent_color = "#56B375"
#incongruent_color = "#791E94"
incongruent_color = "#9046CF"
```

```{r}
#for the dots on the graphs
round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}
```

generate CSVs from RDS

```{r}
library(dplyr)
library(stringr)
library(tidyverse)
library(bbmle)      # for ICtab()


correct_stim_list = c("sound/DADA.wav" = "bouba",
                      "sound/MAMA.wav" = "bouba",
                      "sound/SASA.wav" = "bouba",
                      "sound/didi.wav" = "bouba",
                      "sound/sisi.wav" = "bouba",
                      "sound/mimi.wav" = "bouba",
                      "sound/FAFA.wav" = "bouba",
                      "sound/fifi.wav" = "bouba",
                      "sound/zizi.wav" = "kiki",
                      "sound/titi.wav" = "kiki",
                      "sound/TATA.wav" = "kiki",
                      "sound/KAKA.wav" = "kiki",
                      "sound/kiki.wav" = "kiki",
                      "sound/LALA.wav" = "bouba",
                      "sound/lili.wav" = "bouba",
                      "sound/ZAZA.wav" = "kiki")


	
	
left_key = "z"
right_key = "m"

which_is_correct <- function(stimuli,lefts,rights) {
  
  #Make a new vector the same length as the number of rows
  correct_vec <- rep(NA,length(stimuli))
  
  #For each row in the dataset....
  for(i in seq(1:length(stimuli))){
    
    #Get the correct type ("Bouba" or "Kiki") by checking in the stim list
    correct_type <- correct_stim_list[stimuli[i]]
    
    #If the correct type is in the left one the correct key was the left key
    if(grepl(correct_type, lefts[i], fixed = TRUE)){
      correct_key <- left_key
    }
    #If the correct type is in the right one the correct key was the right key
    else if(grepl(correct_type, rights[i], fixed = TRUE)){
      correct_key <- right_key
    }
    #If it isn't in either something has gone wrong so you'll get an NA
    else{
      correct_key <- NA
    }
    
    #Put that correct key in the output vector
    correct_vec[i] <- correct_key
  }
  
  #Return the final filled in vector
  return(correct_vec)
}

#look at the results files

rds_files <- list.files("bko2 full paradigm RDS",
                        pattern = "\\.rds$",
                        full.names = TRUE)

rds_files

for(file in rds_files){
  print(file)
  file_id <- str_extract(file,"bkp\\d\\d\\d")
  #this IS case sensitve, change all RDS names to lowercase 
  
  data <- readRDS(file)
  
  #assign ID
  participant_ID <- data$results$`sp_id`[[1]]
  main_data <- data$results$`Main page`[[1]]
  
  
  df <- read.table(text = main_data, sep =",", header = TRUE, stringsAsFactors = FALSE)
  #df is the raw data, tells you stimulus and responses
  
  
  ##Ben Code ***creating tidy data and choice bias score***
  
  #First remove unneeded columns
  data_cols <- df %>% dplyr::select(c(trial_type,stimulus,response,left_image,right_image,correct_response,correct)) 
  
  #Then Filter practice and experimental trials
  data_prac <- data_cols %>% filter(grepl("Prac", stimulus, fixed = TRUE))
  data_exp <- data_cols %>% filter(!grepl("Prac", stimulus, fixed = TRUE)) %>%
    filter(trial_type  %in% c("bouba-kiki","image-keyboard-response")) %>%
    filter(stimulus != "img/fixation.png")
  
  #filter out BK data 
  data_exp_bk <-data_exp %>% filter(trial_type == "bouba-kiki")
  #filter out the LG data
  data_exp_lg <-data_exp %>% filter(trial_type =="image-keyboard-response") %>%
    dplyr::select(c(trial_type, stimulus, response))
  
  #Now write a function to find if the left or the right image is "correct"
  
  
  data_exp_bk <- data_exp_bk %>% mutate(correct_response = which_is_correct(stimulus,left_image,right_image))
  data_exp_bk <- data_exp_bk %>% mutate(correct = ifelse(correct_response == response,
                                                         1,
                                                         ifelse(response == left_key | response == right_key,
                                                                0,
                                                                NA)))
  
  data_exp_bk <- data_exp_bk %>% mutate(sound = ifelse(stimulus %in% c("sound/DADA.wav","sound/MAMA.wav",
                                                                 "sound/SASA.wav","sound/didi.wav",
                                                                 "sound/sisi.wav","sound/mimi.wav",
                                                                 "sound/FAFA.wav","sound/fifi.wav","sound/LALA.wav",
                                                                 "sound/lili.wav"),"curved",
                                                 ifelse(stimulus %in% c("sound/zizi.wav","sound/titi.wav",
                                                                        "sound/TATA.wav","sound/KAKA.wav",
                                                                        "sound/kiki.wav","sound/ZAZA.wav"),"angular",
                                                        NA))) %>% filter(!is.na(correct))
  
  data_exp_bk <- data_exp_bk %>% mutate(vowel_type = ifelse(stimulus %in% c("sound/DADA.wav","sound/MAMA.wav",
                                                                       "sound/SASA.wav","sound/TATA.wav",
                                                                       "sound/KAKA.wav","sound/ZAZA.wav",
                                                                       "sound/FAFA.wav","sound/LALA.wav"),"/a/",
                                                       
                                                       ifelse(stimulus %in% c("sound/zizi.wav","sound/titi.wav",
                                                                              "sound/didi.wav","sound/sisi.wav",
                                                                              "sound/kiki.wav","sound/fifi.wav",
                                                                              "sound/lili.wav","sound/mimi.wav"),"/i/",
                                                              NA))) %>% filter(!is.na(correct))
  
  data_exp_bk <- data_exp_bk %>% mutate(congruent = ifelse(stimulus %in% c("sound/DADA.wav","sound/MAMA.wav",
                                                                            "sound/SASA.wav","sound/zizi.wav",
                                                                            "sound/kiki.wav","sound/LALA.wav",
                                                                            "sound/FAFA.wav","sound/titi.wav"),"congruent",
                                                            
                                                            ifelse(stimulus %in% c("sound/TATA.wav","sound/lili.wav",
                                                                                   "sound/didi.wav","sound/sisi.wav",
                                                                                   "sound/KAKA.wav","sound/fifi.wav",
                                                                                   "sound/ZAZA.wav","sound/mimi.wav"),"incongruent",
                                                                   NA))) %>% filter(!is.na(correct))
  
  data_exp_bk <- data_exp_bk %>% mutate(voicing = ifelse(stimulus %in% c("sound/DADA.wav","sound/MAMA.wav",
                                                                           "sound/LALA.wav","sound/zizi.wav",
                                                                           "sound/didi.wav","sound/lili.wav",
                                                                           "sound/ZAZA.wav","sound/mimi.wav"),"voiced",
                                                           
                                                           ifelse(stimulus %in% c("sound/TATA.wav","sound/SASA.wav",
                                                                                  "sound/kiki.wav","sound/sisi.wav",
                                                                                  "sound/KAKA.wav","sound/fifi.wav",
                                                                                  "sound/FAFA.wav","sound/titi.wav"),"unvoiced",
                                                                  NA))) %>% filter(!is.na(correct))
  
  data_exp_bk <- data_exp_bk %>% mutate(consonant_type = ifelse(stimulus %in% c("sound/DADA.wav","sound/didi.wav",
                                                                         "sound/TATA.wav","sound/titi.wav",
                                                                         "sound/kiki.wav","sound/KAKA.wav"), "stop",
                                                   ifelse(stimulus %in% c("sound/MAMA.wav","sound/LALA.wav",
                                                                        "sound/lili.wav","sound/mimi.wav"),"sonorant",
                                                         
                                                         ifelse(stimulus %in% c("sound/SASA.wav","sound/ZAZA.wav",
                                                                                "sound/sisi.wav","sound/zizi.wav",
                                                                                "sound/fifi.wav", "sound/FAFA.wav"),"fricative",
                                                                NA)))) %>% filter(!is.na(correct))
  
  
  
  #file pathing
  file_path_bk <- paste0("bko2 full paradigm CSVs/",file_id,"_bk.csv")

  file_path_prac <- paste0("bko2 full paradigm practice trials/",file_id,".csv")
  write.csv(data_prac, file_path_prac)
  
  write.csv(data_exp_bk, file_path_bk) 

}

```

Make them into one big data frame
```{r}
all_files <- list.files("bko2 full paradigm CSVs")
first_file <- TRUE

#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
  if(grepl("b",all_files[i])){
    print(all_files[i])
    if(first_file){
      all_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
      all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
      first_file <- FALSE
    }
    else{
      new_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
      new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
      all_data_df <- rbind(all_data_df,new_data_df)
    }
  }
}

#filter out the NAs
all_data_df <- all_data_df %>% filter(!is.na(correct))

unique(all_data_df$ID)
left_key = "z"
right_key = "m"
```

add in ages
```{r}
age_table <- read_excel("bko2 age table.xlsx")
all_data_df <- full_join(all_data_df,age_table, by="ID")
```
add in WJ scores
```{r}
WJ_scores <- read_excel("WJ scores.xlsx")
all_data_df <- full_join(all_data_df,WJ_scores, by="ID")
```

#choice bias calculations
```{r}
#CALCULATE CHOICE BIAS
#group_by(ID,sound,group) group for when i have both adults and children
all_data_df <- all_data_df %>% mutate(shape_choice = ifelse(grepl("bouba",left_image)  & response == left_key,
                                                         1,
                                                         ifelse(grepl("bouba",right_image)  & response == right_key, 1,
                                                         0))) 

#write an excel file for all this with library("xlsx")
#write.xlsx(all_data_df, file = "bko2 all trials df.xlsx")


data_orth <- all_data_df %>% group_by(ID,sound,Range) %>%
  summarise(bias = sum(shape_choice)/n()-.5)

data_all_sounds <- all_data_df %>% group_by(ID,sound,stimulus) %>%
  summarise(bias = sum(shape_choice)/n()-.5)

data_vowel_type <- all_data_df %>% group_by(vowel_type, ID,Range) %>%
  summarise(bias = sum(shape_choice)/n()-.5)

data_congruency = all_data_df %>% group_by(congruent, ID,Range) %>%
  summarise(bias = sum(correct)/n())

data_voicing = all_data_df %>% group_by(voicing, ID,Range) %>%
  summarise(bias = sum(shape_choice)/n()-.5)

data_consonant = all_data_df %>% group_by(consonant_type, ID,Range) %>%
  summarise(bias = sum(shape_choice)/n()-.5)
```
How many trials did each participant get?
```{r}
all_data_df %>% filter(ID == "bkp025") #need to check about the number of trials each participant got
trial_counts <- all_data_df %>% group_by(ID) %>%
                               summarize(trial_counts = n())
#mean(trial_counts$trial_counts)
#[1] 31.48438
```


```{r}
stimulus_bias_data <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,stimulus,sound,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n() - 0.5) %>% 
                                      group_by(stimulus,sound,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n()),
                                                N = n()) %>%
                                      ungroup() %>%
                                      mutate(stimulus = fct_reorder2(stimulus, sound, mean_bias))

stimulus_bias_data_points <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,stimulus,sound,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n() - 0.5) %>% 
                                      ungroup() %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(stimulus,sound,bias) %>%
                                      summarise(Count = n())
```

#ALL STIM GRAPH

```{r}

new_color_all_stim <- ggplot() +
  geom_col(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias), color = "black", fill = NA) +
  geom_point(stimulus_bias_data_points, mapping =aes(x = stimulus, y = bias, size = Count, color= sound)) +
  geom_col(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias, fill = sound), alpha = 0.5) +
  geom_point(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias)) +
  geom_errorbar(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1) +
  scale_fill_manual(values = c(angular_color,curved_color)) +
  scale_color_manual(values = c(angular_color,curved_color)) +
  theme_classic() +
  ylim(-0.5,0.5) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  ylab("Choice Bias") +
  xlab("Stimulus") +
  facet_wrap("Range")

new_color_all_stim
#ggsave("graphs/presentation graphs/kids_all_stim.png", width = 10, height = 5)
```
ANALYSIS WITH BONFERONNI CORRECTION 
```{r}
#stimulus:Range gets you the interaction term, which is the difference from 0 for each stimulus for each age range
#the nAGQ = 0 is a bit mysterious, might be too many people at 100% correct that makes the model fail to converge but this makes it work
stim_m <- glmer(shape_choice ~ 0 + stimulus:Range + (1 | ID), data = all_data_df, family = binomial, nAGQ = 0)
summary(stim_m)


#bonferroni correction
#16 stimuli * 3 different age ranges
stim_tib <- tibble(categories = row.names(summary(stim_m)$coefficients),
                  old_p = summary(stim_m)$coefficients[,4],
                  p_vals = p.adjust(summary(stim_m)$coefficients[,4], method = "bonferroni", n = 16*3),
                  p_val_print = sprintf("%.10f", p_vals),
                  sig = ifelse(p_vals<0.05, "significant", "nonsignificant"))
stim_tib

```


#orthography graph
```{r}
                                      
orth_new <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,sound,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n()- 0.5) %>%  
                                      group_by(sound,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n()),
                                                N=n()) 

orth_new_points <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,sound,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n()- 0.5) %>% 
                                      ungroup() %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(sound,bias_round) %>%
                                      summarise(Count = n())

new_orthography <- ggplot(data_orth, aes(x = sound, y = bias)) +
  geom_col(orth_new, mapping = aes(x = sound, y = mean_bias), color = "black", fill = NA) +
  geom_point(orth_new_points, mapping = aes(x = sound, y = bias_round, size = Count, color = sound)) +
  geom_col(orth_new, mapping = aes(x = sound, y = mean_bias, fill = sound), alpha = 0.5) +
  geom_point(orth_new, mapping = aes(x = sound, y = mean_bias)) +
  geom_errorbar(orth_new, mapping = aes(x = sound, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
#stat_compare_means(comparisons = orth_comparisons, label.y = c(1),
                    #label = "p.signif", hide.ns = FALSE) +
  theme_light() +
  ylim(-.5, .5) +
  scale_fill_manual(values = c(angular_color,curved_color)) +
  scale_color_manual(values = c(angular_color,curved_color)) +
  scale_size_continuous(breaks = c(5, 10, 15)) +
  ylab("Relative choice bias in expected direction") +
  xlab("Pseudoword Orthography") +
  facet_wrap("Range")

new_orthography

#ggsave("graphs/presentation graphs/sig orthography.png", height = 3.5, width = 3.5)

```
how to tell if the age groups are different from each other

```{r}
#by range. mixed effect binary model
m_mult <- glmer(shape_choice ~ Range*sound + (1|ID), data = all_data_df, family = "binomial")
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 
#IC tab multiplies the residuals by the number of terms, higher number is worse
#ICtab(m_mult, m_add)

Anova(m_mult)

contrast(emmeans(m_mult, ~ Range | sound) , method = "pairwise", type = "response")
bko2_range_difference_table <-contrast(emmeans(m_mult, ~ Range | sound) , method = "pairwise", type = "response")

```

#orthography IS THERE A SIGNIFICANT DIFFERENCE FROM 0?
 you want to see if every group is different from zero, and so you want a model that just looks at the smallest groups (each sound for each age group), with none of the big groupings. that’s why you just look at the interaction, not sound*range. This is doing those 6 individual t tests, and correcting for the number of t tests at the same time. 
```{r}
#sound:Range gets you the interaction term, which is the difference from 0 for each stimulus for each age range
stim_o <- glmer(shape_choice ~ 0 + sound:Range + (1|ID), data = all_data_df, family = binomial)
summary(stim_o)

```

#CONGRUENCY GRAPH
```{r}
#using correct since it doesn't matter how round or sharp they think something is based on congruency, but it is interesting if they got things right or not based on congruency
data_congruency_sound = all_data_df %>% group_by(congruent, ID,Range,sound) %>%
  summarise(bias = sum(correct)/n())

#need to make these different colors
congruency_new <- all_data_df %>% group_by(congruent, ID,Range) %>% 
                                      summarise(bias = sum(correct)/n()) %>% 
                                      group_by(congruent,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n())) 

congruency_new_points <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(congruent, ID,Range) %>% 
                                      summarise(bias = sum(correct)/n()) %>% 
                                      ungroup() %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(congruent,bias_round,Range) %>%
                                      summarise(Count = n())

congruency_plot_new <- ggplot(data_congruency, aes(x = congruent, y = bias)) +
  geom_col(congruency_new, mapping = aes(x = congruent, y = mean_bias), color = "black", fill = NA) +
  geom_point(congruency_new_points, mapping = aes(x = congruent, y = bias_round, size = Count, color = congruent)) +
  geom_col(congruency_new, mapping = aes(x = congruent, y = mean_bias, fill = congruent), alpha = 0.5) +
  geom_point(congruency_new, mapping = aes(x = congruent, y = mean_bias)) +
  geom_errorbar(congruency_new, mapping = aes(x = congruent, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  #geom_jitter(data_congruency_sound, mapping = aes(x = congruent, y = bias))+
  scale_fill_manual(values = c(congruent_color,incongruent_color)) +
  scale_color_manual(values = c(congruent_color,incongruent_color)) +
  theme_light() +
  ylim(0,1) +
  ylab("Proportion of correct choices (accuracy)") +
  #scale_y_continuous(limits = c(0, 1), breaks = c(0.00, 0.25, 0.50, 0.75, 1)) +
  xlab("Pseudoword congruency") +
  facet_wrap("Range")

congruency_plot_new
#ggsave("graphs/presentation graphs/congruency_plot_new.png", height = 3.5, width = 3.5)
```
analysis
how to tell if the age groups are different from each other

```{r}
#by range. is there a difference between bias for congruent/incongruent words for different age ranges?
m_mult_c <- glmer(correct ~ Range*congruent + (1|ID), data = all_data_df, family = "binomial")
#m_add_c <- glm(bias ~ Range+congruent, data = data_congruency)
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 
#IC tab multiplies the residuals by the number of terms, higher number is worse
#ICtab(m_mult_c, m_add_c)

Anova(m_mult_c)

contrast(emmeans(m_mult_c, ~ Range | congruent) , method = "pairwise", type = "response")
#bko1_range_difference_table <-contrast(emmeans(m_add_c, ~ Range | sound) , method = "pairwise", type = "response")
```
analysis
how to tell if there is a difference between congruent and incongruent for each age group
```{r}
#model of only the interaction term
congruency_i <- glmer(correct ~ congruent:Range + (1|ID), data = all_data_df, family = "binomial")
summary(congruency_i)

Anova(congruency_i)

#this will tell you what the differences are between congruent/incongruent for each age range
contrast(emmeans(congruency_i, ~ congruent | Range) , method = "pairwise", type = "response") #order of terms matters here, difference in congruent for each age range

```

#GRAPH FOR VOWEL TYPE
```{r}
#
data_vowel_type <- all_data_df %>% group_by(vowel_type, ID,Range) %>%
  summarise(bias = sum(shape_choice)/n()-.5)

vowel_type_mean <- data_vowel_type %>%  group_by(vowel_type,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n())) 

vowel_points <- data_vowel_type %>% group_by(vowel_type, Range) %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(vowel_type,bias_round) %>%
                                      summarise(Count = n())
#graph
vowel_plot <- ggplot(data_vowel_type, aes(x = vowel_type, y = bias)) +
  geom_col(vowel_type_mean, mapping = aes(x = vowel_type, y = mean_bias), color = "black", fill = NA) +
  geom_point(vowel_points, mapping = aes(x = vowel_type, y = bias_round, size = Count, color = vowel_type)) +
  #geom_jitter(data_vowel_type, mapping = aes(x = vowel_type, y = bias))+

  geom_col(vowel_type_mean, mapping = aes(x = vowel_type, y = mean_bias, fill = vowel_type), alpha = 0.5) +
  geom_point(vowel_type_mean, mapping = aes(x = vowel_type, y = mean_bias)) +
  geom_errorbar(vowel_type_mean, mapping = aes(x = vowel_type, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  theme_classic() +
  ylim(-.5,.5) +
  scale_fill_manual(values = c(curved_color,angular_color)) +
  scale_color_manual(values = c(curved_color,angular_color)) +
  scale_size_continuous(breaks = c(5, 10, 15)) +
  ylab("Choice bias in expected direction") +
  xlab("Vowel type") +
  facet_wrap("Range")

vowel_plot

#ggsave("graphs/presentation graphs/vowel plot.png", height = 3.5, width = 3.5)
```
#ANALYSIS FOR VOWEL TYPE
```{r}
#by range. is there a difference between bias for vowel  for different age ranges?
m_mult_co <- glmer(shape_choice ~ Range*vowel_type + (1|ID), data = all_data_df, family = "binomial")
#m_add_co <- glm(bias ~ Range+vowel_type, data = data_vowel_type)
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 
#IC tab multiplies the residuals by the number of terms, higher number is worse
#ICtab(m_mult_co, m_add_co)

Anova(m_mult_co)

contrast(emmeans(m_mult_co, ~ Range | vowel_type) , method = "pairwise", type = "response")

###########difference from chance?
stim_v <- glmer(shape_choice ~ 0 + vowel_type:Range + (1|ID), data = all_data_df, family = "binomial") 
summary(stim_v)

```
# GRAPH FOR CONSONANT VOICING
```{r}
#
data_voicing = all_data_df %>% group_by(voicing, ID,Range) %>%
  summarise(bias = sum(shape_choice)/n()-.5)

voicing_mean <- all_data_df %>%  group_by(voicing,ID,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n()-.5) %>% 
                                      group_by(voicing,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n())) 

voicing_points <- all_data_df %>% group_by(voicing,ID,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n()-.5) %>% 
                                      ungroup() %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(voicing,bias_round) %>%
                                      summarise(Count = n())

voicing_plot <- ggplot(data_voicing, aes(x = voicing, y = bias)) +
  geom_col(voicing_mean, mapping = aes(x = voicing, y = mean_bias), color = "black", fill = NA) +
  geom_point(voicing_points, mapping = aes(x = voicing, y = bias_round, size = Count, color = voicing)) +
  geom_col(voicing_mean, mapping = aes(x = voicing, y = mean_bias, fill = voicing), alpha = 0.5) +
  geom_point(voicing_mean, mapping = aes(x = voicing, y = mean_bias)) +
  geom_errorbar(voicing_mean, mapping = aes(x = voicing, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  theme_light() +
  ylim(-.5,.5) +
  scale_fill_manual(values = c(curved_color,angular_color)) +
  scale_color_manual(values = c(curved_color,angular_color)) +
  scale_size_continuous(breaks = c(5, 10, 15)) +
  ylab("Choice Bias in expected direction") +
  xlab("Consonant voicing")+
  facet_wrap("Range")

voicing_plot

#ggsave("graphs/presentation graphs/voicing plot.png", height = 3.5, width = 3.5)
```
#ANALYSIS FOR CONSONANT VOICING
```{r}
#by range. is there a difference between bias for vowel  for different age ranges?
m_mult_cv <- glmer(shape_choice ~ Range*voicing + (1|ID), data = all_data_df, family = "binomial")
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 
#IC tab multiplies the residuals by the number of terms, higher number is worse
#ICtab(m_mult_cv, m_add_cv)

Anova(m_mult_cv)

contrast(emmeans(m_mult_cv, ~ Range | voicing) , method = "pairwise", type = "response")

## which ones are different form zero?
cv_binom <- glmer(shape_choice ~ 0 + Range:voicing + (1|ID), data = all_data_df, family = "binomial")
summary(cv_binom)

```

#consonant graph 
for one is in the style of Bottini et al 2019 with the proportion of spiky shapes, see previous version, bko2 thesis graphs and analysis

Graph in Vivian's style, with it split at 0
```{r}
#
data_split_consonant_type = all_data_df %>% group_by(consonant_type, ID,Range) %>%
                                      summarise(bias = sum(shape_choice)/n()- 0.5) 

#df for graphing
consonant_graph_df_split <- data_split_consonant_type %>% group_by(consonant_type,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n()), 
                                                N = n()) 
#df for points
consonant_graph_points <- data_split_consonant_type %>% mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(consonant_type,bias_round) %>%
                                      summarise(Count = n())


#graph
consonant_graph <- ggplot(data_split_consonant_type, aes(x = consonant_type, y = bias)) +
  geom_col(consonant_graph_df_split, mapping = aes(x = consonant_type, y = mean_bias), color = "black", fill = NA) +
  geom_point(consonant_graph_points, mapping = aes(x = consonant_type, y = bias_round, size = Count, color = consonant_type)) +
  #geom_jitter(data_split_consonant_type, mapping = aes(x = consonant_type, y = bias))+
  geom_col(consonant_graph_df_split, mapping = aes(x = consonant_type, y = mean_bias, fill = consonant_type), alpha = 0.5) +
  geom_point(consonant_graph_df_split, mapping = aes(x = consonant_type, y = mean_bias)) +
  geom_errorbar(consonant_graph_df_split, mapping = aes(x = consonant_type, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  theme_light() +
  ylim(-.5,.5) +
  scale_fill_manual(values = c(angular_color,curved_color,third_color)) +
  scale_color_manual(values = c(angular_color,curved_color,third_color)) +
  scale_size_continuous(breaks = c(5, 10, 15)) +
  #stat_compare_means(comparisons = consonant_comparisons, label.y = c(1.1, 1.3, 1.5),
                    #label = "p.signif", hide.ns = FALSE) +
  ylab("Relative bias in expected direction") +
  xlab("Consonant type")+
  facet_wrap("Range")

consonant_graph

```


#ANALYSIS FOR CONSONANT TYPE
```{r}
#by range. is there a difference between bias for consonant_type  for different age ranges?
m_mult_co <- glmer(shape_choice ~ Range*consonant_type + (1|ID), data = all_data_df, family = "binomial")
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 
#IC tab multiplies the residuals by the number of terms, higher number is worse
#ICtab(m_mult_co, m_add_co)

Anova(m_mult_co)

contrast(emmeans(m_mult_co, ~ Range | consonant_type) , method = "pairwise", type = "response")

```

Are they different from chance (50 %) or

IS THERE A SIGNIFICANT DIFFERENCE FROM 0?
 you want to see if every group is different from zero, and so you want a model that just looks at the smallest groups (each sound for each age group), with none of the big groupings. that’s why you just look at the interaction, not sound*range. This is doing those 6 individual t tests, and correcting for the number of t tests at the same time. 
```{r}
#consonant_type:Range gets you the interaction term, which is the difference from 0 for each stimulus for each age range
#ben mess
real_binom <- glmer(shape_choice ~ 0 + Range:consonant_type + (1|ID), data = all_data_df, family = "binomial")
summary(real_binom)
#plogis(0.3830)
       
```


#WJ SCORE ANALYSIS 
```{r}
#get one row per participant with one average score (average of all trials)
data_WJ <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
  summarise(bias = mean(correct))

ggplot(data_WJ,aes(x = WJ_score, y = bias, color = Age))+
  geom_point()+
  #geom_smooth(se = FALSE, method = "glm", formula = "y ~ poly(x,2)")+
  geom_smooth(se = FALSE, method = "glm")+
  scale_color_viridis_b ()+
  theme_light()+
  ylab("Strength of bouba-kiki bias")+
  xlab("Score on the Woodcock Johnson task")

#binned by range?
ggplot(data_WJ,aes(x = WJ_score, y = bias, color = Age))+
  geom_point()+
  geom_smooth(se = FALSE, method = "glm")+
  scale_color_viridis_b()+
  theme_light()+
  facet_wrap("Range")

cor.test(data_WJ$WJ_score, data_WJ$bias)
#there is a significant correlation between bias and WJ score
```


random effects???

```{r}
library(lme4)
```

Partial correlation tells you if it's still significant controlling for that third variable, then you should include it in the model. partial correlation is the overlap between IV and DV circles- how much it explains the variance. if there is a significant effect controlling for age, you should include age in the regression analysis. 
Might also want to do semi partial- it excludes the overlap with the outcome variability due to age. 
check with how Rsquared is interpreted

```{r}
# the (1|...) means Age is being included in the model as a random effect. This evens it out to see if the WJ-Bias correlation is still significant with Age taken into account. 
#still need to add in ages of all adults
bias_WJ_glmm <- lmer(bias ~ WJ_score + (1|Age), data = data_WJ)
Anova(bias_WJ_glmm)
summary(bias_WJ_glmm)

#fixed effect model
bias_WJ_glmm_fixed <- glm(bias ~ WJ_score + Age, data = data_WJ)

Anova(bias_WJ_glmm_fixed)
summary(bias_WJ_glmm_fixed)

#comparing models?
ICtab(bias_WJ_glmm,bias_WJ_glmm_fixed)

#partial correlation? 

#library(ppcor)
pcor.test(data_WJ$WJ_score,data_WJ$bias,data_WJ$Age,method="pearson")

spcor.test(data_WJ$WJ_score,data_WJ$bias,data_WJ$Age,method="pearson")

```
looking at each age range individually

```{r}
#try this binned by age, for each age range
#get one row per participant with one average score (average of all trials) for 6-8 year olds only
data_WJ_6to8 <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
              filter(Range == "6 to 8") %>%
              summarise(bias = mean(correct))

#fixed effect model
bias_WJ_glmm_fixed_6to8 <- glm(bias ~ WJ_score + Age, data = data_WJ_6to8)

Anova(bias_WJ_glmm_fixed_6to8)
summary(bias_WJ_glmm_fixed_6to8)

#regular correlation
cor.test(data_WJ_6to8$WJ_score,data_WJ_6to8$bias,method="pearson")
#partial and semipartial controlling for age
pcor.test(data_WJ_6to8$WJ_score,data_WJ_6to8$bias,data_WJ_6to8$Age,method="pearson")


#########################9 to 11####
#get one row per participant with one average score (average of all trials) for 6-8 year olds only
data_WJ_9to11 <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
              filter(Range == "9 to 11") %>%
              summarise(bias = mean(correct))

#fixed effect model
bias_WJ_glmm_fixed_9to11 <- glm(bias ~ WJ_score + Age, data = data_WJ_9to11)

Anova(bias_WJ_glmm_fixed_9to11)
summary(bias_WJ_glmm_fixed_9to11)

#regular correlation
cor.test(data_WJ_9to11$WJ_score,data_WJ_9to11$bias,method="pearson")
#partial correlation controlling for age
pcor.test(data_WJ_9to11$WJ_score,data_WJ_9to11$bias,data_WJ_9to11$Age,method="pearson")


#########################adult####
#get one row per participant with one average score (average of all trials) for 6-8 year olds only
data_WJ_adult <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
              filter(Range == "Adult") %>%
              summarise(bias = mean(correct))

#fixed effect model
bias_WJ_glmm_fixed_adult <- glm(bias ~ WJ_score + Age, data = data_WJ_adult)

Anova(bias_WJ_glmm_fixed_adult)
summary(bias_WJ_glmm_fixed_adult)

#regular correlation
cor.test(data_WJ_adult$WJ_score,data_WJ_adult$bias,method="pearson")
#partial correlation controlling for age
pcor.test(data_WJ_adult$WJ_score,data_WJ_adult$bias,data_WJ_adult$Age,method="pearson")


```
look at only in kids (filter out adults)
```{r}
#########################kids only####
#get one row per participant with one average score (average of all trials) for all kids
data_WJ_kids <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
              filter(!(Range == "Adult")) %>%
              summarise(bias = mean(correct))

#fixed effect model
bias_WJ_glmm_fixed_kids <- glm(bias ~ WJ_score + Age, data = data_WJ_kids)

Anova(bias_WJ_glmm_fixed_kids)
summary(bias_WJ_glmm_fixed_kids)

#regular correlation
cor.test(data_WJ_kids$WJ_score,data_WJ_kids$bias,method="pearson")
#partial correlation controlling for age
pcor.test(data_WJ_kids$WJ_score,data_WJ_kids$bias,data_WJ_kids$Age,method="pearson")


#semi partial correlation? 
#library(ppcor)
spcor.test(data_WJ_kids$WJ_score,data_WJ_kids$bias,data_WJ_kids$Age,method="pearson")
```

#Inter-rater reliability
```{r}
# 3 raters, not the same rater for each subject
#IRR, or ICC? 
#ICC needs to be two-way, consistency not agreement, single unit
library("irr")

data("anxiety", package = "irr")
head(anxiety, 4)

ICC_data <- read_excel("reliability scoring.xlsx")
icc(
  ICC_data, model = "twoway", 
  type = "consistency", unit = "single"
  )

library(psych)
#gives a more detailed chart?
ICC(ICC_data)
```



