First we create the graph of all the 16 stimuli


```{r}
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(forcats)
library(emmeans)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)
library("writexl")
library(viridis)
library(ppcor) #for partial correlation

```
Colors
```{r}
angular_color = "#E01A4F"
curved_color = "#FFC05C"
third_color = "#80B8EF"
```

```{r}
round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}
```

generate CSVs

```{r}
library(dplyr)
library(stringr)
library(tidyverse)
library(bbmle)      # for ICtab()


correct_stim_list = c("sound/DADA.wav" = "bouba",
                      "sound/MAMA.wav" = "bouba",
                      "sound/SASA.wav" = "bouba",
                      "sound/didi.wav" = "bouba",
                      "sound/sisi.wav" = "bouba",
                      "sound/mimi.wav" = "bouba",
                      "sound/FAFA.wav" = "bouba",
                      "sound/fifi.wav" = "bouba",
                      "sound/zizi.wav" = "kiki",
                      "sound/titi.wav" = "kiki",
                      "sound/TATA.wav" = "kiki",
                      "sound/KAKA.wav" = "kiki",
                      "sound/kiki.wav" = "kiki",
                      "sound/LALA.wav" = "bouba",
                      "sound/lili.wav" = "bouba",
                      "sound/ZAZA.wav" = "kiki")


	
	
left_key = "z"
right_key = "m"

which_is_correct <- function(stimuli,lefts,rights) {
  
  #Make a new vector the same length as the number of rows
  correct_vec <- rep(NA,length(stimuli))
  
  #For each row in the dataset....
  for(i in seq(1:length(stimuli))){
    
    #Get the correct type ("Bouba" or "Kiki") by checking in the stim list
    correct_type <- correct_stim_list[stimuli[i]]
    
    #If the correct type is in the left one the correct key was the left key
    if(grepl(correct_type, lefts[i], fixed = TRUE)){
      correct_key <- left_key
    }
    #If the correct type is in the right one the correct key was the right key
    else if(grepl(correct_type, rights[i], fixed = TRUE)){
      correct_key <- right_key
    }
    #If it isn't in either something has gone wrong so you'll get an NA
    else{
      correct_key <- NA
    }
    
    #Put that correct key in the output vector
    correct_vec[i] <- correct_key
  }
  
  #Return the final filled in vector
  return(correct_vec)
}

#look at the results files

rds_files <- list.files("bko2 full paradigm RDS",
                        pattern = "\\.rds$",
                        full.names = TRUE)

rds_files

for(file in rds_files){
  print(file)
  file_id <- str_extract(file,"bkp\\d\\d\\d")
  #this IS case sensitve, change all RDS names to lowercase 
  
  data <- readRDS(file)
  
  #assign ID
  participant_ID <- data$results$`sp_id`[[1]]
  main_data <- data$results$`Main page`[[1]]
  
  
  df <- read.table(text = main_data, sep =",", header = TRUE, stringsAsFactors = FALSE)
  #df is the raw data, tells you stimulus and responses
  
  
  ##Ben Code ***creating tidy data and choice bias score***
  
  #First remove unneeded columns
  data_cols <- df %>% select(c(trial_type,stimulus,response,left_image,right_image,correct_response,correct)) 
  
  #Then Filter practice and experimental trials
  data_prac <- data_cols %>% filter(grepl("Prac", stimulus, fixed = TRUE))
  data_exp <- data_cols %>% filter(!grepl("Prac", stimulus, fixed = TRUE)) %>%
    filter(trial_type  %in% c("bouba-kiki","image-keyboard-response")) %>%
    filter(stimulus != "img/fixation.png")
  
  #filter out BK data 
  data_exp_bk <-data_exp %>% filter(trial_type == "bouba-kiki")
  #filter out the LG data
  data_exp_lg <-data_exp %>% filter(trial_type =="image-keyboard-response") %>%
    select(c(trial_type, stimulus, response))
  
  #Now write a function to find if the left or the right image is "correct"
  
  
  data_exp_bk <- data_exp_bk %>% mutate(correct_response = which_is_correct(stimulus,left_image,right_image))
  data_exp_bk <- data_exp_bk %>% mutate(correct = ifelse(correct_response == response,
                                                         1,
                                                         ifelse(response == left_key | response == right_key,
                                                                0,
                                                                NA)))
  
  data_exp_bk <- data_exp_bk %>% mutate(sound = ifelse(stimulus %in% c("sound/DADA.wav","sound/MAMA.wav",
                                                                 "sound/SASA.wav","sound/didi.wav",
                                                                 "sound/sisi.wav","sound/mimi.wav",
                                                                 "sound/FAFA.wav","sound/fifi.wav","sound/LALA.wav",
                                                                 "sound/lili.wav"),"curved",
                                                 ifelse(stimulus %in% c("sound/zizi.wav","sound/titi.wav",
                                                                        "sound/TATA.wav","sound/KAKA.wav",
                                                                        "sound/kiki.wav","sound/ZAZA.wav"),"angular",
                                                        NA))) %>% filter(!is.na(correct))
  
  data_exp_bk <- data_exp_bk %>% mutate(vowel_type = ifelse(stimulus %in% c("sound/DADA.wav","sound/MAMA.wav",
                                                                       "sound/SASA.wav","sound/TATA.wav",
                                                                       "sound/KAKA.wav","sound/ZAZA.wav",
                                                                       "sound/FAFA.wav","sound/LALA.wav"),"/a/",
                                                       
                                                       ifelse(stimulus %in% c("sound/zizi.wav","sound/titi.wav",
                                                                              "sound/didi.wav","sound/sisi.wav",
                                                                              "sound/kiki.wav","sound/fifi.wav",
                                                                              "sound/lili.wav","sound/mimi.wav"),"/i/",
                                                              NA))) %>% filter(!is.na(correct))
  
  data_exp_bk <- data_exp_bk %>% mutate(congruent = ifelse(stimulus %in% c("sound/DADA.wav","sound/MAMA.wav",
                                                                            "sound/SASA.wav","sound/zizi.wav",
                                                                            "sound/kiki.wav","sound/LALA.wav",
                                                                            "sound/FAFA.wav","sound/titi.wav"),"congruent",
                                                            
                                                            ifelse(stimulus %in% c("sound/TATA.wav","sound/lili.wav",
                                                                                   "sound/didi.wav","sound/sisi.wav",
                                                                                   "sound/KAKA.wav","sound/fifi.wav",
                                                                                   "sound/ZAZA.wav","sound/mimi.wav"),"incongruent",
                                                                   NA))) %>% filter(!is.na(correct))
  
  data_exp_bk <- data_exp_bk %>% mutate(voicing = ifelse(stimulus %in% c("sound/DADA.wav","sound/MAMA.wav",
                                                                           "sound/LALA.wav","sound/zizi.wav",
                                                                           "sound/didi.wav","sound/lili.wav",
                                                                           "sound/ZAZA.wav","sound/mimi.wav"),"voiced",
                                                           
                                                           ifelse(stimulus %in% c("sound/TATA.wav","sound/SASA.wav",
                                                                                  "sound/kiki.wav","sound/sisi.wav",
                                                                                  "sound/KAKA.wav","sound/fifi.wav",
                                                                                  "sound/FAFA.wav","sound/titi.wav"),"unvoiced",
                                                                  NA))) %>% filter(!is.na(correct))
  
  data_exp_bk <- data_exp_bk %>% mutate(consonant_type = ifelse(stimulus %in% c("sound/DADA.wav","sound/didi.wav",
                                                                         "sound/TATA.wav","sound/titi.wav",
                                                                         "sound/kiki.wav","sound/KAKA.wav"), "stop",
                                                   ifelse(stimulus %in% c("sound/MAMA.wav","sound/LALA.wav",
                                                                        "sound/lili.wav","sound/mimi.wav"),"sonorant",
                                                         
                                                         ifelse(stimulus %in% c("sound/SASA.wav","sound/ZAZA.wav",
                                                                                "sound/sisi.wav","sound/zizi.wav",
                                                                                "sound/fifi.wav", "sound/FAFA.wav"),"fricative",
                                                                NA)))) %>% filter(!is.na(correct))
  
  
  
  #file pathing
  file_path_bk <- paste0("bko2 full paradigm CSVs/",file_id,"_bk.csv")

  file_path_prac <- paste0("bko2 full paradigm practice trials/",file_id,".csv")
  write.csv(data_prac, file_path_prac)
  
  write.csv(data_exp_bk, file_path_bk) 

}


```


```{r}
all_files <- list.files("bko2 full paradigm CSVs")
first_file <- TRUE

#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
  if(grepl("b",all_files[i])){
    print(all_files[i])
    if(first_file){
      all_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
      all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
      first_file <- FALSE
    }
    else{
      new_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
      new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
      all_data_df <- rbind(all_data_df,new_data_df)
    }
  }
}

#filter out the NAs
all_data_df <- all_data_df %>% filter(!is.na(correct))

unique(all_data_df$ID)
left_key = "z"
right_key = "m"
```

add in ages
```{r}
age_table <- read_excel("bko2 age table.xlsx")
all_data_df <- full_join(all_data_df,age_table, by="ID")
```
add in WJ scores
```{r}
WJ_scores <- read_excel("WJ scores.xlsx")
all_data_df <- full_join(all_data_df,WJ_scores, by="ID")
```


```{r}
#CALCULATE CHOICE BIAS
#group_by(ID,sound,group) group for when i have both adults and children
data_orth <- all_data_df %>% group_by(ID,sound,Range) %>%
  summarise(bias = sum(correct)/n())

data_all_sounds <- all_data_df %>% group_by(ID,sound,stimulus) %>%
  summarise(bias = sum(correct)/n())

data_vowel_type <- all_data_df %>% group_by(vowel_type, ID,Range) %>%
  summarise(bias = sum(correct)/n())

data_congruency = all_data_df %>% group_by(congruent, ID,Range) %>%
  summarise(bias = sum(correct)/n())

data_voicing = all_data_df %>% group_by(voicing, ID,Range) %>%
  summarise(bias = sum(correct)/n())

data_consonant = all_data_df %>% group_by(consonant_type, ID,Range) %>%
  summarise(bias = sum(correct)/n())

#data_consonant_type = all_data_df_c %>% group_by(consonant_type, ID) %>%
  #summarise(bias = sum(sharp_shape_choice)/n())
```

```{r}
#listing comparisons for significance bars
#bias for orthography
orth_comparisons <- list( c("6 to 8", "9 to 11", "Adult"))

#bias for vowel type
vowel_comparisions <- list( c("/a/", "/i/"))

#bias for congruency
congruency_comparisions <- list( c("congruent", "incongruent"))

#bias for voicing
voicing_comparisions <- list( c("unvoiced", "voiced"))

#bias for consonant type
consonant_comparisons <- list( c("stop", "fricative"),
                        c("fricative", "sonorant"),
                        c("stop", "sonorant"))

```


```{r}
#all_data_df <- read.csv("all_data_df.csv")
#this csv file has lala and lili as angular 
```

```{r}
stimulus_bias_data <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,stimulus,sound,Range) %>% 
                                      summarise(bias = sum(correct)/n() - 0.5) %>% 
                                      mutate(bias = ifelse(sound == "angular",-1*bias,bias)) %>%
                                      group_by(stimulus,sound,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n()),
                                                N = n()) %>%
                                      ungroup() %>%
                                      mutate(stimulus = fct_reorder2(stimulus, sound, mean_bias))

stimulus_bias_data_points <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,stimulus,sound,Range) %>% 
                                      summarise(bias = sum(correct)/n() - 0.5) %>% 
                                      ungroup() %>%
                                      mutate(bias = ifelse(sound == "angular",-1*bias,bias)) %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(stimulus,sound,bias) %>%
                                      summarise(Count = n())
```

ALL STIM GRAPH

```{r}

new_color_all_stim <- ggplot() +
  geom_col(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias), color = "black", fill = NA) +
  geom_point(stimulus_bias_data_points, mapping =aes(x = stimulus, y = bias, size = Count, color= sound)) +
  geom_col(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias, fill = sound), alpha = 0.5) +
  geom_point(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias)) +
  geom_errorbar(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1) +
  scale_fill_manual(values = c(angular_color,curved_color)) +
  scale_color_manual(values = c(angular_color,curved_color)) +
  theme_classic() +
  ylim(-0.5,0.5) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  ylab("Choice Bias") +
  xlab("Stimulus") +
  facet_wrap("Range")

new_color_all_stim
#ggsave("graphs/presentation graphs/kids_all_stim.png", width = 10, height = 5)
```
ANALYSIS WITH BONFERONNI CORRECTION 
```{r}
#stimulus:Range gets you the interaction term, which is the difference from 0 for each stimulus for each age range
stim_m <- glm(correct ~ 0 + stimulus:Range, data = all_data_df, family = binomial)
summary(stim_m)#$coefficients[,4]


#bonferroni correction
stim_tib <- tibble(categories = row.names(summary(stim_m)$coefficients),
                  old_p = summary(stim_m)$coefficients[,4],
                  p_vals = p.adjust(summary(stim_m)$coefficients[,4], method = "bonferroni", n = 16*3),
                  p_val_print = sprintf("%.10f", p_vals),
                  sig = ifelse(p_vals<0.05, "significant", "nonsignificant"))
stim_tib

```



orthography graph
```{r}
                                      
orth_new <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,sound,Range) %>% 
                                      summarise(bias = sum(correct)/n()- 0.5) %>%  
                                      mutate(bias = ifelse(sound == "angular",-1*bias,bias)) %>%
                                      group_by(sound,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n())) 

orth_new_points <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,sound,Range) %>% 
                                      summarise(bias = sum(correct)/n()- 0.5) %>% 
                                      ungroup() %>%
                                      mutate(bias = ifelse(sound == "angular",-1*bias,bias)) %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(sound,bias_round) %>%
                                      summarise(Count = n())

new_orthography <- ggplot(data_orth, aes(x = sound, y = bias)) +
  geom_col(orth_new, mapping = aes(x = sound, y = mean_bias), color = "black", fill = NA) +
  geom_point(orth_new_points, mapping = aes(x = sound, y = bias_round, size = Count, color = sound)) +
  geom_col(orth_new, mapping = aes(x = sound, y = mean_bias, fill = sound), alpha = 0.5) +
  geom_point(orth_new, mapping = aes(x = sound, y = mean_bias)) +
  geom_errorbar(orth_new, mapping = aes(x = sound, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
#stat_compare_means(comparisons = orth_comparisons, label.y = c(1),
                    #label = "p.signif", hide.ns = FALSE) +
  theme_classic() +
  ylim(-.5, .5) +
  scale_fill_manual(values = c(angular_color,curved_color)) +
  scale_color_manual(values = c(angular_color,curved_color)) +
  scale_size_continuous(breaks = c(5, 10, 15)) +
  ylab("Choice Bias") +
  xlab("Sound") +
  facet_wrap("Range")

new_orthography

#ggsave("graphs/presentation graphs/sig orthography.png", height = 3.5, width = 3.5)

```
How to tell if the bars as graphed are different form each other- is the opposite direction of them strong enough? The direction is significantly in the expected direction 
```{r}

```



how to tell if the age groups are different from each other

```{r}
#by range
m_range <- glm(bias ~ Range, data = data_orth)
m_sound <- glm(bias ~ sound, data = data_orth)
m_mult <- glm(bias ~ Range*sound, data = data_orth)
m_add <- glm(bias ~ Range+sound, data = data_orth)
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 
#IC tab multiplies the residuals by the number of terms, higher number is worse
ICtab(m_range,m_sound,m_mult, m_add)

Anova(m_mult)

contrast(emmeans(m_mult, ~ Range | sound) , method = "pairwise", type = "response")
bko1_range_difference_table <-contrast(emmeans(m_mult, ~ Range | sound) , method = "pairwise", type = "response")


```

IS THERE A SIGNIFICANT DIFFERENCE FROM 0?
 you want to see if every group is different from zero, and so you want a model that just looks at the smallest groups (each sound for each age group), with none of the big groupings. thatâ€™s why you just look at the interaction, not sound*range. This is doing those 6 individual t tests, and correcting for the number of t tests at the same time. 
```{r}
#sound:Range gets you the interaction term, which is the difference from 0 for each stimulus for each age range
stim_o <- glm(bias ~ 0 + sound:Range, data = data_orth, family = binomial)
summary(stim_o)


#bonferroni correction, not sure if necessary for only 6 t tests so disregard this
stim_tib <- tibble(categories = row.names(summary(stim_m)$coefficients),
                  old_p = summary(stim_m)$coefficients[,4],
                  p_vals = p.adjust(summary(stim_m)$coefficients[,4], method = "bonferroni", n = 16*3),
                  p_val_print = sprintf("%.10f", p_vals),
                  sig = ifelse(p_vals<0.05, "significant", "nonsignificant"))
stim_tib

```

CONGRUENCY GRAPH

```{r}
congruency_new <- all_data_df %>% group_by(congruent, ID,Range) %>% 
                                      summarise(bias = sum(correct)/n()) %>% 
                                      #mutate(bias = ifelse(congruent == "incongruent",-1*bias,bias)) %>%
                                      #ungroup()%>%
                                      group_by(congruent,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n())) 

congruency_new_points <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(congruent, ID,Range) %>% 
                                      summarise(bias = sum(correct)/n()) %>% 
                                      ungroup() %>%
                                      #mutate(bias = ifelse(congruent == "incongruent",-1*bias,bias)) %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(congruent,bias_round,Range) %>%
                                      summarise(Count = n())

congruency_plot_new <- ggplot(data_congruency, aes(x = congruent, y = bias)) +
  geom_col(congruency_new, mapping = aes(x = congruent, y = mean_bias), color = "black", fill = NA) +
  geom_point(congruency_new_points, mapping = aes(x = congruent, y = bias_round, size = Count, color = congruent)) +
  geom_col(congruency_new, mapping = aes(x = congruent, y = mean_bias, fill = congruent), alpha = 0.5) +
  geom_point(congruency_new, mapping = aes(x = congruent, y = mean_bias)) +
  geom_errorbar(congruency_new, mapping = aes(x = congruent, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  #stat_compare_means(comparisons = congruency_comparisions, label.y = c(1.2),
                    #label = "p.signif", hide.ns = TRUE) +
  scale_fill_manual(values = c(angular_color,curved_color)) +
  scale_color_manual(values = c(angular_color,curved_color)) +
  theme_classic() +
  #ylim(-0.5,0.5) +
  ylab("Choice Bias") +
  scale_y_continuous(limits = c(0, 1.5), breaks = c(0.00, 0.25, 0.50, 0.75, 1)) +
  xlab("Congruency") +
  facet_wrap("Range")

congruency_plot_new
#ggsave("graphs/presentation graphs/congruency_plot_new.png", height = 3.5, width = 3.5)
```
analysis
how to tell if the age groups are different from each other

```{r}
#by range. is there a difference between bias for congruent/incongruent words for different age ranges?
m_range_c <- glm(bias ~ Range, data = data_congruency)
m_sound_c <- glm(bias ~ congruent, data = data_congruency)
m_mult_c <- glm(bias ~ Range*congruent, data = data_congruency)
m_add_c <- glm(bias ~ Range+congruent, data = data_congruency)
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 
#IC tab multiplies the residuals by the number of terms, higher number is worse
ICtab(m_range_c,m_sound_c,m_mult_c, m_add_c)

Anova(m_add_c)

contrast(emmeans(m_add_c, ~ Range | congruent) , method = "pairwise", type = "response")
#bko1_range_difference_table <-contrast(emmeans(m_add_c, ~ Range | sound) , method = "pairwise", type = "response")
```
analysis
how to tell if there is a difference between congruent and incongruent for each age group
```{r}
congruency_a <- glm(bias ~congruent+Range, data = data_congruency)
congruency_m <- glm(bias ~congruent*Range, data = data_congruency)
#model of only the interaction term
congruency_i <- glm(bias ~congruent:Range, data = data_congruency)

Anova(congruency_i)

#this will tell you what the differences are between congruent/incongruent for each age range
contrast(emmeans(congruency_i, ~ congruent | Range) , method = "pairwise", type = "response") #order of terms matters here, difference in congruent for each age range

```

GRAPH FOR VOWEL TYPE
```{r}
vowel_type_mean <- all_data_df %>%  group_by(vowel_type,ID) %>% 
                                      summarise(bias = sum(correct)/n()) %>% 
                                      #mutate(bias = ifelse(vowel_type == "/i/",-1*bias,bias)) %>%
                                      group_by(vowel_type) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n())) 

vowel_points <- all_data_df %>% group_by(vowel_type,ID) %>% 
                                      summarise(bias = sum(correct)/n()) %>% 
                                      ungroup() %>%
                                      #mutate(bias = ifelse(vowel_type == "/i/",-1*bias,bias)) %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(vowel_type,bias_round) %>%
                                      summarise(Count = n())

vowel_plot <- ggplot(data_vowel_type, aes(x = vowel_type, y = bias)) +
  geom_col(vowel_type_mean, mapping = aes(x = vowel_type, y = mean_bias), color = "black", fill = NA) +
  geom_point(vowel_points, mapping = aes(x = vowel_type, y = bias_round, size = Count, color = vowel_type)) +
  geom_col(vowel_type_mean, mapping = aes(x = vowel_type, y = mean_bias, fill = vowel_type), alpha = 0.5) +
  geom_point(vowel_type_mean, mapping = aes(x = vowel_type, y = mean_bias)) +
  geom_errorbar(vowel_type_mean, mapping = aes(x = vowel_type, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  stat_compare_means(comparisons = vowel_comparisions, label.y = c(1.2),
                    label = "p.signif", hide.ns = TRUE) +
  theme_classic() +
  ylim(0, 1.5) +
  scale_fill_manual(values = c(curved_color,angular_color)) +
  scale_color_manual(values = c(curved_color,angular_color)) +
  scale_size_continuous(breaks = c(5, 10, 15)) +
  ylab("Choice Bias") +
  xlab("Vowel type")

vowel_plot

#ggsave("graphs/presentation graphs/vowel plot.png", height = 3.5, width = 3.5)
```
ANALYSIS FOR VOWEL TYPE
```{r}
#what is the difference between /a/ and /i/?
# One-sample t-test
vow <- t.test(bias ~ vowel_type, data = data_vowel_type)
# Printing the results
vow 
```
GRAPH FOR CONSONANT VOICING
```{r}
voicing_mean <- all_data_df %>%  group_by(voicing,ID,Range) %>% 
                                      summarise(bias = sum(correct)/n()) %>% 
                                      #mutate(bias = ifelse(voicing == "/i/",-1*bias,bias)) %>%
                                      group_by(voicing) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n())) 

voicing_points <- all_data_df %>% group_by(voicing,ID,Range) %>% 
                                      summarise(bias = sum(correct)/n()) %>% 
                                      ungroup() %>%
                                      #mutate(bias = ifelse(voicing == "/i/",-1*bias,bias)) %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(voicing,bias_round) %>%
                                      summarise(Count = n())

voicing_plot <- ggplot(data_voicing, aes(x = voicing, y = bias)) +
  geom_col(voicing_mean, mapping = aes(x = voicing, y = mean_bias), color = "black", fill = NA) +
  geom_point(voicing_points, mapping = aes(x = voicing, y = bias_round, size = Count, color = voicing)) +
  geom_col(voicing_mean, mapping = aes(x = voicing, y = mean_bias, fill = voicing), alpha = 0.5) +
  geom_point(voicing_mean, mapping = aes(x = voicing, y = mean_bias)) +
  geom_errorbar(voicing_mean, mapping = aes(x = voicing, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  #stat_compare_means(comparisons = voicing_comparisions, label.y = c(1.2),
                    #label = "p.signif", hide.ns = TRUE) +
  theme_classic() +
  ylim(0, 1.5) +
  scale_fill_manual(values = c(curved_color,angular_color)) +
  scale_color_manual(values = c(curved_color,angular_color)) +
  scale_size_continuous(breaks = c(5, 10, 15)) +
  ylab("Choice Bias") +
  xlab("Consonant voicing")+
  facet_wrap("Range")

voicing_plot

#ggsave("graphs/presentation graphs/voicing plot.png", height = 3.5, width = 3.5)
```
ANALYSIS FOR CONSONANT VOICING
```{r}
# One-sample t-test
voi <- t.test(bias ~ voicing, data = data_voicing)
# Printing the results
voi 
```
consonant type

```{r}
#bias for consonant type
consonant_comparisons <- list( c("stop", "fricative"),
                        c("fricative", "sonorant"),
                        c("stop", "sonorant"))
                        

ggplot(data_consonant, aes(x = consonant_type, y = bias)) +
  geom_boxplot() +
  #  facet_wrap(~ group) +
  stat_summary(fun.y=mean, geom="point", shape=20, size=5, color="black", fill="black") +
  ylim(0,2) +
  theme_light()+
  stat_compare_means(comparisons = consonant_comparisons, label.y = c(1.1, 1.3, 1.5),
                     label = "p.signif", hide.ns = TRUE)
```

I need to know: how often was a round shape chosen when given each of the 3 consonant types?
first add column to all_data_df

```{r}
all_data_df_c <- all_data_df %>% mutate(round_shape_choice = ifelse(grepl("bouba",left_image)  & response == left_key,
                                                         1,
                                                         ifelse(grepl("bouba",right_image)  & response == right_key, 1,
                                                         0))) %>% 
  mutate(sharp_shape_choice = ifelse(grepl("kiki",left_image)  & response == left_key,
                                                         1,
                                                         ifelse(grepl("kiki",right_image)  & response == right_key, 1,
                                                         0)))
```

make consonant graph


consonant_graph_df <- all_data_df_c %>% group_by(ID,consonant_type) %>% 
                                      summarise(bias = sum(sharp_shape_choice)/n()) %>% 
                                      #mutate(bias = ifelse(sound == "angular",-1*bias,bias)) %>%
                                      group_by(consonant_type) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n())) 

consonant_graph_points <- all_data_df_c %>% group_by(ID,consonant_type) %>% 
                                      summarise(bias = sum(sharp_shape_choice)/n()) %>% 
                                      ungroup() %>%
                                      #mutate(bias = ifelse(sound == "angular",-1*bias,bias)) %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(consonant_type,bias_round) %>%
                                      summarise(Count = n())

consonant_graph <- ggplot(data_consonant_type, aes(x = consonant_type, y = bias)) +
  geom_col(consonant_graph_df, mapping = aes(x = consonant_type, y = mean_bias), color = "black", fill = NA) +
  geom_point(consonant_graph_points, mapping = aes(x = consonant_type, y = bias_round, size = Count, color = consonant_type)) +
  geom_col(consonant_graph_df, mapping = aes(x = consonant_type, y = mean_bias, fill = consonant_type), alpha = 0.5) +
  geom_point(consonant_graph_df, mapping = aes(x = consonant_type, y = mean_bias)) +
  geom_errorbar(consonant_graph_df, mapping = aes(x = consonant_type, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  theme_classic() +
  ylim(0,1.8) +
  scale_fill_manual(values = c(angular_color,curved_color,third_color)) +
  scale_color_manual(values = c(angular_color,curved_color,third_color)) +
  scale_size_continuous(breaks = c(5, 10, 15)) +
  stat_compare_means(comparisons = consonant_comparisons, label.y = c(1.1, 1.3, 1.5),
                    label = "p.signif", hide.ns = FALSE) +
  ylab("Proportion of sharp shape choices") +
  xlab("consonant type")

consonant_graph

#ggsave("graphs/presentation graphs/consonant_type.png", width = 5, height = 3)

ANALYSIS FOR CONSONANT TYPE

m_c <- glm(sharp_shape_choice ~ consonant_type, data = all_data_df_c)

Anova(m_c)

contrast(emmeans(m_c, ~ consonant_type) , method = "pairwise", type = "response")

bko2_consonant_table <-contrast(emmeans(m_c, ~ consonant_type) , method = "pairwise", type = "response")

write.csv(bko2_consonant_table, "significance tables/bko2_consonant_table.csv")
```


ggplot(data_consonant, aes(x = consonant_type, y = bias)) +
  geom_boxplot() +
  #  facet_wrap(~ group) +
  stat_summary(fun.y=mean, geom="point", shape=20, size=5, color="black", fill="black") +
  ylim(0,2) +
  theme_light()+
  stat_compare_means(comparisons = consonant_comparisons, label.y = c(1.1, 1.3, 1.5),
                     label = "p.signif", hide.ns = TRUE)
```

WJ SCORE ANALYSIS 
```{r}
#get one row per participant with one average score (average of all trials)
data_WJ <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
  summarise(bias = mean(correct))

#all_data_df %>% filter(ID == "bkp025") need to check about the number of trials each participant got

ggplot(data_WJ,aes(x = WJ_score, y = bias, color = Age))+
  geom_point()+
  #geom_smooth(se = FALSE, method = "glm", formula = "y ~ poly(x,2)")+
  geom_smooth(se = FALSE, method = "glm")+
  scale_color_viridis()+
  theme_classic()

#binned by range?
ggplot(data_WJ,aes(x = WJ_score, y = bias, color = Age))+
  geom_point()+
  geom_smooth(se = FALSE, method = "glm")+
  scale_color_viridis()+
  theme_classic()+
  facet_wrap("Range")

cor.test(data_WJ$WJ_score, data_WJ$bias)
#there is a significant correlation between bias and WJ score
```


random effects???

```{r}
library(lme4)
```

Partial correlation tells you if it's still significant controlling for that third variable, then you should include it in the model. partial correlation is the overlap between IV and DV circles- how much it explains the variance. if there is a significant effect controlling for age, you should include age in the regression analysis. 
Might also want to do semi partial- it excludes the overlap with the outcome variability due to age. 
check with how Rsquared is interpreted

```{r}
# the (1|...) means Age is being included in the model as a random effect. This evens it out to see if the WJ-Bias correlation is still significant with Age taken into account. 
#still need to add in ages of all adults
bias_WJ_glmm <- lmer(bias ~ WJ_score + (1|Age), data = data_WJ)
Anova(bias_WJ_glmm)
summary(bias_WJ_glmm)

#fixed effect model
bias_WJ_glmm_fixed <- glm(bias ~ WJ_score + Age, data = data_WJ)

Anova(bias_WJ_glmm_fixed)
summary(bias_WJ_glmm_fixed)

#comparing models?
ICtab(bias_WJ_glmm,bias_WJ_glmm_fixed)

#partial correlation? 

#library(ppcor)
spcor.test(data_WJ$WJ_score,data_WJ$bias,data_WJ$Age,method="pearson")

```


```{r}
#try this binned by age, for each age range
#get one row per participant with one average score (average of all trials) for 6-8 year olds only
data_WJ_6to8 <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
              filter(Range == "6 to 8") %>%
              summarise(bias = mean(correct))

#fixed effect model
bias_WJ_glmm_fixed_6to8 <- glm(bias ~ WJ_score + Age, data = data_WJ_6to8)

Anova(bias_WJ_glmm_fixed_6to8)
summary(bias_WJ_glmm_fixed_6to8)

#regular correlation
cor.test(data_WJ_6to8$WJ_score,data_WJ_6to8$bias,method="pearson")

#partial correlation? 
#library(ppcor)
pcor.test(data_WJ_6to8$WJ_score,data_WJ_6to8$bias,data_WJ_6to8$Age,method="pearson")

#########################9 to 11####
#get one row per participant with one average score (average of all trials) for 6-8 year olds only
data_WJ_9to11 <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
              filter(Range == "9 to 11") %>%
              summarise(bias = mean(correct))

#fixed effect model
bias_WJ_glmm_fixed_9to11 <- glm(bias ~ WJ_score + Age, data = data_WJ_9to11)

Anova(bias_WJ_glmm_fixed_9to11)
summary(bias_WJ_glmm_fixed_9to11)

#regular correlation
cor.test(data_WJ_9to11$WJ_score,data_WJ_9to11$bias,method="pearson")

#partial correlation? 
#library(ppcor)
pcor.test(data_WJ_9to11$WJ_score,data_WJ_9to11$bias,data_WJ_9to11$Age,method="pearson")

#########################adult####
#get one row per participant with one average score (average of all trials) for 6-8 year olds only
data_WJ_adult <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
              filter(Range == "Adult") %>%
              summarise(bias = mean(correct))

#fixed effect model
bias_WJ_glmm_fixed_adult <- glm(bias ~ WJ_score + Age, data = data_WJ_adult)

Anova(bias_WJ_glmm_fixed_adult)
summary(bias_WJ_glmm_fixed_adult)

#regular correlation
cor.test(data_WJ_adult$WJ_score,data_WJ_adult$bias,method="pearson")

#partial correlation? 
#library(ppcor)
pcor.test(data_WJ_adult$WJ_score,data_WJ_adult$bias,data_WJ_adult$Age,method="pearson")
```

