Including the 5 year olds as their own age range
also trying to bin the age ranges by age, instad of age range 
also taking the graphs in the Poirel 2011 style (global-local scores)
In previous versions, there is code to use only the first half of the trials (using slice) to make sure participants     weren't doing different things

#libraries and variables
```{r}
library(dplyr)
library(stringr)
library(tidyverse)
library(bbmle)      # for ICtab()
library(readxl)
library("writexl")
library(ggplot2)
library(ggpubr)
library(lme4)       #for glmer
library(car)        # for Anova()
library(emmeans)
library(report)




left_key = "z"
right_key = "m"

round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}

correct_stim_list = c("sound/baba_rep.wav" = "bouba",
                      "sound/gaga_rep.wav" = "bouba",
                      "sound/keekee.wav" = "kiki",
                      "sound/teetee.wav" = "kiki")


which_is_correct <- function(stimuli,lefts,rights) {
  
  #Make a new vector the same length as the number of rows
  correct_vec <- rep(NA,length(stimuli))
  
  #For each row in the dataset....
  for(i in seq(1:length(stimuli))){
    
    #Get the correct type ("Bouba" or "Kiki") by checking in the stim list
    correct_type <- correct_stim_list[stimuli[i]]
    
    #If the correct type is in the left one the correct key was the left key
    if(grepl(correct_type, lefts[i], fixed = TRUE)){
      correct_key <- left_key
    }
    #If the correct type is in the right one the correct key was the right key
    else if(grepl(correct_type, rights[i], fixed = TRUE)){
      correct_key <- right_key
    }
    #If it isn't in either something has gone wrong so you'll get an NA
    else{
      correct_key <- NA
    }
    
    #Put that correct key in the output vector
    correct_vec[i] <- correct_key
  }
  
  #Return the final filled in vector
  return(correct_vec)
}

```
#Colors
This assigns HEX codes for all the colors in the graph
```{r}
angular_color = "#E01A4F"
curved_color = "#FFC05C"
third_color = "#80B8EF"
congruent_color = "#56B375"
incongruent_color = "#9046CF"
```


generating the csvs:
```{r }
#look at the results files
#this data set in LG_DI_five_rds is NON CONFOUND ONLY- 16 5, 20 6-8, 24 9-11, 41 adults
rds_files <- list.files("LG_DI_five_rds",
                        pattern = "\\.rds$",
                        full.names = TRUE)

rds_files
#change [#] to pick which one to read

for(file in rds_files){
  print(file)
  file_id <- str_extract(file,"b[kl]g\\d\\d\\d")
  
  data <- readRDS(file)
  
  #assign ID
  participant_ID <- data$results$`sp_id`[[1]]
  main_data <- data$results$`Main page`[[1]]
  
  
  df <- read.table(text = main_data, sep =",", header = TRUE, stringsAsFactors = FALSE)
  #df is the raw data, tells you stimulus and responses
  
  
  ##Ben Code ***creating tidy data and choice bias score***
  
  #First remove unneeded columns
  data_cols <- df %>% dplyr::select(c(trial_type,stimulus,response,left_image,right_image,correct_response,correct)) 
  
  #Then Filter practice and experimental trials
  data_prac <- data_cols %>% filter(grepl("Prac", stimulus, fixed = TRUE))
  data_exp <- data_cols %>% filter(!grepl("Prac", stimulus, fixed = TRUE)) %>%
    filter(trial_type  %in% c("bouba-kiki","image-keyboard-response")) %>%
    filter(stimulus != "img/fixation.png")
  
  #filter out BK data 
  data_exp_bk <-data_exp %>% filter(trial_type == "bouba-kiki")
  #filter out the LG data
  data_exp_lg <-data_exp %>% filter(trial_type =="image-keyboard-response") %>%
    dplyr::select(c(trial_type, stimulus, response))
  
  #Now write a function to find if the left or the right image is "correct"
  
  data_exp_bk <- data_exp_bk %>% mutate(correct_response = which_is_correct(stimulus,left_image,right_image))
  data_exp_bk <- data_exp_bk %>% mutate(correct = ifelse(correct_response == response,
                                                         1,
                                                         ifelse(response == left_key | response == right_key,
                                                                0,
                                                                NA)))
  
  data_exp_bk <- data_exp_bk %>% mutate(sound = ifelse(stimulus %in% c("sound/baba_rep.wav","sound/gaga_rep.wav"),
                                                       "round",
                                                       ifelse(stimulus %in% c("sound/teetee.wav","sound/keekee.wav"),
                                                              "spiky",
                                                              NA))) %>%
    filter(!is.na(correct))
  
#adding columns to LG files to do analysis ############
  data_exp_lg <- data_exp_lg %>% separate(stimulus, c("type","image_ID"), sep = "/") 
  
  data_exp_lg <- data_exp_lg %>% group_by(type) %>% 
                                mutate(trial_num = row_number()) %>% 
                                ungroup() %>%
                                pivot_wider(names_from = type, values_from = c(image_ID,response)) %>%
                                dplyr::select(!c(trial_type,response_targets))

  
  
  
  
  file_path_bk <- paste0("LG_DI_five_bk_csv/",file_id,"_bk.csv")
  file_path_lg <- paste0("LG_DI_five_csv/",file_id,"_lg.csv")
  
  file_path_prac <- paste0("LG practice trials/",file_id,".csv")
  #write.csv(data_prac, file_path_prac)
  
  #write.csv(data_exp_bk, file_path_bk) 
  #write.csv(data_exp_lg, file_path_lg)
  
}


```


#create lg df
```{r}

all_files <- list.files("LG_DI_five_csv")
first_file <- TRUE

#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
  if(grepl("lg",all_files[i])){
    print(all_files[i])
    if(first_file){
      LG_data_df <- read.csv(paste0("LG_DI_five_csv/",all_files[i]))
      LG_data_df <- LG_data_df %>% mutate(ID = substr(all_files[i],1,6))
      first_file <- FALSE
    }
    else{
      LGnew_data_df <- read.csv(paste0("LG_DI_five_csv/",all_files[i]))
      LGnew_data_df <- LGnew_data_df %>% mutate(ID = substr(all_files[i],1,6))
      LG_data_df <- rbind(LG_data_df,LGnew_data_df)
    }
  }
}

#unique(LG_data_df$ID) #at 101 June 5
```

#create bk df
```{r}
#this is for all LG analyses with BK correlation
all_files <- list.files("LG_DI_five_bk_csv")
first_file <- TRUE

#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
  if(grepl("lg",all_files[i])){
    print(all_files[i])
    if(first_file){
      bk_data_df <- read.csv(paste0("LG_DI_five_bk_csv/",all_files[i]))
      bk_data_df <- bk_data_df %>% mutate(ID = substr(all_files[i],1,6))
      first_file <- FALSE
    }
    else{
      bknew_data_df <- read.csv(paste0("LG_DI_five_bk_csv/",all_files[i]))
      bknew_data_df <- bknew_data_df %>% mutate(ID = substr(all_files[i],1,6))
      bk_data_df <- rbind(bk_data_df,bknew_data_df)
    }
  }
}

#unique(LG_data_df$ID) #at 101 June 5

#first create a new column shape_choice that has a 1 if they chose round, 0 if they chose spiky
bk_data_df <- bk_data_df %>% mutate(shape_choice = ifelse(grepl("bouba",left_image)  & response == left_key,
                                                         1,
                                                         ifelse(grepl("bouba",right_image)  & response == right_key, 1,
                                                         0))) 



```

#create bk replication df
```{r}
#this gets 3 of the bko folder (the first 3 participants run)
#need to then add this to the online only participants from the LG dataset
all_files <- list.files("replication csv files")
first_file <- TRUE

#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
  if(grepl("bk",all_files[i])){
    print(all_files[i])
    if(first_file){
      bk_rep_df <- read.csv(paste0("replication csv files/",all_files[i]))
      bk_rep_df <- bk_rep_df %>% mutate(ID = substr(all_files[i],1,6))
      first_file <- FALSE
    }
    else{
      bknew_rep_df <- read.csv(paste0("replication csv files/",all_files[i]))
      bknew_rep_df <- bknew_rep_df %>% mutate(ID = substr(all_files[i],1,6))
      bk_rep_df <- rbind(bk_rep_df,bknew_rep_df)
    }
  }
}

#unique(LG_data_df$ID) #at 101 June 5

#first create a new column shape_choice that has a 1 if they chose round, 0 if they chose spiky
bk_rep_df <- bk_rep_df %>% mutate(shape_choice = ifelse(grepl("bouba",left_image)  & response == left_key,
                                                         1,
                                                         ifelse(grepl("bouba",right_image)  & response == right_key, 1,
                                                         0))) 


```



#lg age and other tables
```{r}
#load in the tables of targets and pairs descriptions
target_table <- read_excel("LG_target_table.xlsx")
pairs_table <- read_excel("LG_pair_table.xlsx")
age_table <- read_excel("LG_ages_5.xlsx")
age_table <- age_table %>% mutate(ID = tolower(ID)) #%>% select(ID,Age,Range)

#full_join to combine
LG_data_df_combined <- full_join(LG_data_df,target_table, by="image_ID_targets")
#LG_data_df has no confound image IDs so they are populating as NAs
LG_data_df_combined <- full_join(LG_data_df_combined,pairs_table, by="image_ID_pairs")%>%
  filter(!is.na(ID))
LG_data_df_combined <- full_join(LG_data_df_combined,age_table, by="ID")
#if the the global choice is on the left and they make the "z" response, then put G in the choice column, etc
LG_data_df_combined_bias <- LG_data_df_combined %>% mutate(choice = ifelse(response_pairs == left_key &
                                                                             target_global == pair_left_global,
                                                                           "global", 
                                                                           ifelse(response_pairs == left_key &
                                                                                    target_local == pair_left_local,
                                                                                  "local",
                                                                         ifelse(response_pairs == right_key &
                                                                                  target_global == pair_right_global,
                                                                                "global",
                                                                          ifelse(response_pairs == right_key &
                                                                                    target_local == pair_right_local,
                                                                                  "local",
                                                                                 NA)))))
LG_data_df_combined_bias <- LG_data_df_combined_bias %>% filter(!is.na(choice))
LG_data_df_combined_bias <- LG_data_df_combined_bias %>% mutate(choice_number = ifelse(choice == "global", 1, 0)) %>%
                            filter(!is.na(choice))


# deletes the second half of adults we ran to get the dataset to 25 instead of 41
lglast_half_adults <- unique((LG_data_df_combined_bias %>% filter( Range == "Adult"))$ID)[26:41]

LG_data_df_combined_bias <- LG_data_df_combined_bias %>% filter(!ID %in% lglast_half_adults)

#write.csv(LG_data_df_combined_bias, "significance tables/full data set.csv")
```

#How many trials did each participant get?
```{r}
#need to check about the number of trials each participant got
trial_counts <- LG_data_df_combined_bias %>% group_by(ID) %>%
                               summarize(trial_counts = n()) %>%
                                ungroup() %>%
                              summarize(mean = mean(trial_counts),
                                      sd = sd(trial_counts),
                                      se = sd/sqrt(n()))
#23.74257 average

trial_counts_bk <- bk_data_df %>% group_by(ID) %>%
                               summarize(trial_counts = n()) %>%
                                ungroup() %>%
                              summarize(mean = mean(trial_counts),
                                      sd = sd(trial_counts),
                                      se = sd/sqrt(n()))
#31.76238 average
```

#calculate g-l
new calculation: sum(global)-sum(local)

need to group_by(ID, choice)
```{r}
#creates a count of g - l responses, puts them into categories based on what the end number is (local or global group)
#one row per participant
LG_count <-LG_data_df_combined_bias %>% group_by(ID) %>% count(choice)
LG_count_p <- LG_count %>% pivot_wider(names_from = choice, values_from = n) %>% mutate_all(~replace(., is.na(.), 0))
#new column with local-global
LG_count_p <- LG_count_p %>% mutate(GminusL = global-local) %>% mutate(LG_group = ifelse(GminusL >0, "global", "local"))

```
adding the local-global value to the LG_data_df_combined_bias

```{r}
LG_poirel_all <- full_join(LG_data_df_combined_bias, LG_count_p, by ="ID")
```

#graphing, by range
```{r}
#to count choice bias and see how many participants are in each age range
LG_bias_data <- LG_data_df_combined_bias %>% group_by(ID,Range) %>% 
                                    summarise(global_bias = sum(choice_number)/n()) %>% 
                                    group_by(Range) %>%
                                    summarize(mean_bias = mean(global_bias),
                                    sd_bias = sd(global_bias),
                                    se_bias=sd_bias/sqrt(n()),
                                    N=n()) %>% ungroup()

#2 rows for each Range, one local and one global
#instead of LG_poirel_all, try summarizing from an already summarized across participant df
LG_bias_poirel <- LG_poirel_all %>% group_by(ID,Range, LG_group) %>%
                                      summarise(GminusL = mean(GminusL)) %>%
                                    ungroup() %>%
                                    group_by(Range, LG_group) %>%
                                    summarize(mean_bias = mean(GminusL),
                                    sd_bias = sd(GminusL),
                                    n = n(),
                                    se_bias=sd_bias/sqrt(n())) %>% ungroup()




#calculating the points that go on the graph
LG_poirel_points <- LG_poirel_all  %>% group_by(ID,Range, LG_group) %>%
                        mutate(bias_round = round_any(GminusL,5)) %>%  ungroup() %>%
                        group_by(Range,bias_round,LG_group) %>%
                        summarise(Count = length(unique(ID)))


```

# l:g proportion = number in l/g group divided by total N participants in age range #######################
```{r}
#counting number of participants
LG_group_count <- LG_poirel_all %>% group_by(Range, LG_group) %>% summarise(
                                                           count = length(unique(ID)))
LG_group_count_percentage <- LG_group_count %>% pivot_wider(names_from = LG_group, values_from = count)
LG_group_count_percentage <- LG_group_count_percentage %>% group_by(Range) %>% mutate(ratio = global/(local+global))

LG_group_count_p <- full_join(LG_group_count, LG_bias_data, by="Range")
LG_group_count_p <- LG_group_count_p %>% mutate(proportion = count/N)


#average values!! average of GminusL for each age range################
LG_weighted_avg <- LG_poirel_all %>% group_by(ID,Range) %>%
                                      summarise(GminusL = mean(GminusL)) %>%
                                    ungroup() %>%
                                    group_by(Range) %>%
                                    summarise(avg_bias = mean(GminusL),
                                              sd_bias = sd(GminusL, na.rm = TRUE),
                                              se_bias=sd_bias/sqrt(n()), 
                                              N = n()) %>% ungroup()

#make one data set with one row for each participant
LG_bias_poirel_one_row <- LG_poirel_all %>% group_by(ID,Range, LG_group) %>%
                                      summarise(GminusL = mean(GminusL))

```

#lg graph
```{r}

####average GminusL for each age range
LG_poirel_plot2 <-ggplot() +
  geom_col(LG_weighted_avg, mapping = aes(x = Range, y = avg_bias), color = "black", fill = NA) +
  geom_col(LG_weighted_avg, mapping = aes(x = Range, y = avg_bias, fill = Range), alpha = 0.5) +
  geom_errorbar(LG_weighted_avg, mapping = aes(x = Range, y = avg_bias, ymin = avg_bias-se_bias,
                                              ymax = avg_bias+se_bias), alpha = 1, width = .75) +
  geom_point(LG_poirel_points, mapping = aes(x = Range, y = bias_round, size = Count, color = Range)) +
  theme_light() +
  ylab("Global Bias") +
  #scale_color_manual(values = rev(cols)) +
  #scale_fill_manual(values = rev(cols)) +
  xlab("global and local groups in each age range") +
  ylab("<- local bias, global bias ->")

LG_poirel_plot2
```
#analysis- are they different from 0? LG_poirel_plot2
```{r}
#LG_bias_poirel_one_row
lgm1 <- glm(GminusL ~ 0 + Range, data = LG_bias_poirel_one_row)
summary(lgm1)
Anova(lgm1)
report(lgm1)
# none are different from zero


#are they different from each other? no
contrast(emmeans(lgm1, ~ Range) , method = "pairwise", type = "response")

#lg_bias_table <-summary.glm(m1)$coefficients
#write.csv(bko1_bias_table, "significance tables/bko1_bias_table.csv")

#t testing each of the 4 age groups from 0
LG_bias_poirel_one_row %>% group_by(Range) %>%
                       summarise(t_val = t.test(GminusL, mu = 0)$statistic,
                                 df = t.test(GminusL, mu = 0)$parameter,
                                 p_val = t.test(GminusL, mu = 0)$p.value)


```

Is there a significant change in the proportion of L to G participants with age?
```{r}
LG_bias_poirel_one_row <- LG_bias_poirel_one_row %>% mutate(LG_group_bi = ifelse(LG_group == "local", 1,0))

lgm2 <- glm(LG_group_bi ~ 0 + Range, data = LG_bias_poirel_one_row, family = binomial)
summary(lgm2)
Anova(lgm2)
report(lgm2)
#Run the Anova- Age Range does not affect the probability of being local or global

```
#replication graphing
```{r}
#combining datasets. This will make one dataset of 20 adults, 17 online participants from bklg and 3 online participants from bko
rep_ages <- read_excel("bk rep ages.xlsx")
bk_version <- read_xlsx("bko1 version.xlsx")

bk_data_combined <- full_join(bk_data_df,age_table, by="ID")
bk_rep_df <- full_join(bk_rep_df,rep_ages, by="ID")
bk_data_combined <- bk_data_combined %>% filter(!Range =="5")
bk_data_combined_adults <- bk_data_combined %>% filter(Range == "Adult")

bk_adults_for_rep <- full_join(bk_data_combined_adults, bk_version, by = "ID")
bk_adults_for_rep <- bk_adults_for_rep %>% filter(version == "online")
bk_adults_for_rep <- bk_adults_for_rep %>% dplyr::select(!"version")
unique(bk_adults_for_rep$ID)
#bk_adults_for_rep now has only the adults who were run online, now we need to add this to the 3 extra bko participants

bk_rep_df_combined <- rbind(bk_adults_for_rep, bk_rep_df)
unique(bk_rep_df_combined$ID) #now at 20

#get a df that is bk_data_combined but only kids, then add it to bk_rep_df_combined
bk_data_combined_kids <- bk_data_combined %>% filter(!Range =="Adult")
bk_rep_df_combined_full <- rbind(bk_data_combined_kids, bk_rep_df_combined)


bk_rep_bias_data <- bk_rep_df_combined_full %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,sound,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n() - 0.5) %>% 
                                      group_by(sound,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n()),
                                                N = n()) %>%
                                      ungroup() 

bk_rep_bias_data_points <- bk_rep_df_combined_full %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,sound,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n() - 0.5) %>% 
                                      ungroup() %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(Range,sound,bias_round) %>%
                                      summarise(Count = n())

bk_rep_plot <- ggplot() +
  geom_col(bk_rep_bias_data, mapping = aes(x = sound, y = mean_bias), color = "black", fill = NA) +
  geom_point(bk_rep_bias_data_points, mapping =aes(x = sound, y = bias_round, size = Count, color= sound)) +
  geom_col(bk_rep_bias_data, mapping = aes(x = sound, y = mean_bias, fill = sound), alpha = 0.5) +
  geom_errorbar(bk_rep_bias_data, mapping = aes(x = sound, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  scale_fill_manual(values = c(angular_color,curved_color)) +
  scale_color_manual(values = c(angular_color,curved_color)) +
  theme_light() +
  ylim(-0.5,0.5) +
  ylab("Choice bias in expected direction") +
  xlab("Auditory stimulus") +
  facet_wrap("Range")+
  theme(strip.background =element_rect(fill="white"))+
  theme(strip.text = element_text(colour = 'black'))

bk_rep_plot
```
#replication analyses
```{r}
#Different from zero?
#sound:Range gets you the interaction term, which is the difference from 0 for each stimulus for each age range
bk_r_m1 <- glmer(shape_choice ~ 0 + sound:Range + (1|ID), data = bk_rep_df_combined_full, family = binomial)
summary(bk_r_m1)
report(bk_r_m1)
bk_summary<- summary(bk_r_m1)


Corrected_bk <- tibble(categories = row.names(summary(bk_r_m1)$coefficients),
                         p_vals = p.adjust(summary(bk_r_m1)$coefficients[,4], method = "bonferroni", n = 2*4),
                         p_val_print = sprintf("%.10f", p_vals))

rep_bk_tests <- as.data.frame(bk_summary$coefficients) 

#making a table with the corrected p values
rep_bk_tests <- rep_bk_tests %>% mutate(categories = row.names(bk_summary$coefficients),
                                      P.vals = Corrected_bk$p_val_print,
                                      P.vals = as.numeric(P.vals),
                                      P.vals = round(P.vals, digits = 4),
                                      Estimate = round(Estimate, digits = 4),
                                      `Std. Error` = round(`Std. Error`, digits = 4),
                                      `z value` = round(`z value`, digits = 4)) %>%
                                      dplyr::select(!"Pr(>|z|)")

#turn bk_tests into a table
rep_bk_bias_tests <- write.csv(rep_bk_tests, file = "bko1 tables/replication bk tests.csv")

#difference between age groups?
#by range. mixed effect binary model
bk_m2 <- glmer(shape_choice ~ Range*sound + (1|ID), data = bk_rep_df_combined_full, family = "binomial")
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 

Anova(bk_m2)
report(bk_m2)

## |> is a pipe operator in version 4.1, passes to confint() to calculate
contrast(emmeans(bk_m2, ~ Range | sound), method = "pairwise", type = "response") #|> confint()


bk_contrast_table <-contrast(emmeans(bk_m2, ~ Range | sound) , method = "pairwise", type = "response")
bk_contrast_table <- as.data.frame(bk_contrast_table)
bk_contrast_table <- bk_contrast_table %>% mutate(
                                        p.value = round(p.value,digits = 3),
                                        z.ratio = round(z.ratio, digits = 3)) %>%
                                        dplyr::select(!c(df,null))
                                        
bk_bias_contrasts <- write.csv(bk_tests, file = "bko1 tables/replications bk contrasts.csv")

#odds ratio is the effect size- if there is no difference the odds ratio is equal to 1, no effect. If it's farther from 1 in either direction it's more significant
```



#bk Graph for all the stimuli for all age groups individually
```{r}
bk_data_combined <- full_join(bk_data_df,age_table, by="ID")
bk_data_combined <- bk_data_combined %>% filter(!Range =="5")

# deletes the second half of adults we ran to get the dataset to 25 instead of 41
last_half_adults <- unique((bk_data_combined %>% filter( Range == "Adult"))$ID)[26:41]

bk_data_combined <- bk_data_combined %>% filter(!ID %in% last_half_adults)

bk_count <- bk_data_combined %>% group_by(ID) %>% summarise(bias = sum(shape_choice)/n() - 0.5)

bk_bias_data <- bk_data_combined %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,sound,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n() - 0.5) %>% 
                                      group_by(sound,Range) %>%
                                      summarize(mean_bias = mean(bias),
                                                sd_bias = sd(bias),
                                                se_bias=sd_bias/sqrt(n()),
                                                N = n()) %>%
                                      ungroup() 

bk_bias_data_points <- bk_data_combined %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
                                      group_by(ID,sound,Range) %>% 
                                      summarise(bias = sum(shape_choice)/n() - 0.5) %>% 
                                      ungroup() %>%
                                      mutate(bias_round = round_any(bias,0.25)) %>%
                                      group_by(Range,sound,bias_round) %>%
                                      summarise(Count = n())

bk_overall <- ggplot() +
  geom_col(bk_bias_data, mapping = aes(x = sound, y = mean_bias), color = "black", fill = NA) +
  geom_point(bk_bias_data_points, mapping =aes(x = sound, y = bias_round, size = Count, color= sound)) +
  geom_col(bk_bias_data, mapping = aes(x = sound, y = mean_bias, fill = sound), alpha = 0.5) +
  geom_errorbar(bk_bias_data, mapping = aes(x = sound, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1, width = 0.5) +
  scale_fill_manual(values = c(angular_color,curved_color)) +
  scale_color_manual(values = c(angular_color,curved_color)) +
  theme_light() +
  ylim(-0.5,0.5) +
  ylab("Choice bias in expected direction") +
  xlab("Auditory stimulus") +
  facet_wrap("Range")+
  theme(strip.background =element_rect(fill="white"))+
  theme(strip.text = element_text(colour = 'black'))

bk_overall
```

#bk analyses
```{r}
#Different from zero?
#sound:Range gets you the interaction term, which is the difference from 0 for each stimulus for each age range
bk_m1 <- glmer(shape_choice ~ 0 + sound:Range + (1|ID), data = bk_data_combined, family = binomial)
summary(bk_m1)
bk_summary<- summary(bk_m1)


Corrected_bk <- tibble(categories = row.names(summary(bk_m1)$coefficients),
                         p_vals = p.adjust(summary(bk_m1)$coefficients[,4], method = "bonferroni", n = 2*4),
                         p_val_print = sprintf("%.10f", p_vals))

bk_tests <- as.data.frame(bk_summary$coefficients) 

#making a table with the corrected p values
bk_tests <- bk_tests %>% mutate(categories = row.names(bk_summary$coefficients),
                                      P.vals = Corrected_bk$p_val_print,
                                      P.vals = as.numeric(P.vals),
                                      P.vals = round(P.vals, digits = 4),
                                      Estimate = round(Estimate, digits = 4),
                                      `Std. Error` = round(`Std. Error`, digits = 4),
                                      `z value` = round(`z value`, digits = 4)) %>%
                                      dplyr::select(!"Pr(>|z|)")

#turn bk_tests into a table
bk_bias_tests <- write.csv(bk_tests, file = "bko1 tables/bk tests.csv")

#difference between age groups?
#by range. mixed effect binary model
bk_m2 <- glmer(shape_choice ~ Range*sound + (1|ID), data = bk_data_combined, family = "binomial")
#trying to find the model that best fits the data with the least number of terms. not over or under fit to the data. 

Anova(bk_m2)

## |> is a pipe operator in version 4.1, passes to confint() to calculate
contrast(emmeans(bk_m2, ~ Range | sound), method = "pairwise", type = "response") #|> confint()


bk_contrast_table <-contrast(emmeans(bk_m2, ~ Range | sound) , method = "pairwise", type = "response")
bk_contrast_table <- as.data.frame(bk_contrast_table)
bk_contrast_table <- bk_contrast_table %>% mutate(
                                        p.value = round(p.value,digits = 3),
                                        z.ratio = round(z.ratio, digits = 3)) %>%
                                        dplyr::select(!c(df,null))
                                        
bk_bias_contrasts <- write.csv(bk_tests, file = "bko1 tables/bk contrasts.csv")

#odds ratio is the effect size- if there is no difference the odds ratio is equal to 1, no effect. If it's farther from 1 in either direction it's more significant
```
#checking in person and online presentation differences
```{r}


                                                        
```

#comparing bk choice bias to LG bias
use bias scores (GminusL) from LG poirel with 5 yo.R markdown
is there a correlation between your group (local or global group) and your BK bias score?
```{r}
#make a new dataframe with the following columns for each ID: round/spiky bias scores, GminusL scores, LG_group assignment
LG_score_only <- LG_bias_poirel_one_row %>% dplyr::select(ID, Range, GminusL, LG_group) 
#run this below again to include the 5 year olds again
bk_data_combined <- full_join(bk_data_df,age_table, by="ID") %>% na.omit

#what should be calculated??? sum correct, or sum shape choice? shape choice to keep it simple, doens't make a difference
BK_bias_only <- bk_data_combined %>% group_by(ID) %>%
                  mutate(total_bk_bias = sum(shape_choice)/n()-.5) %>% dplyr::select(ID, total_bk_bias)  %>%
                filter(row_number()==1) %>% na.omit

BK_LG_scores <- full_join(LG_score_only, BK_bias_only, by="ID")%>% na.omit

#pearson's correlation 
#make sure the midpoints on each axis is at chance


cor.test <- cor.test(BK_LG_scores$GminusL, BK_LG_scores$total_bk_bias, method = "pearson")
report(cor.test)
#p-value = 0.50

#5 year olds only?
BK_LG_scores_5 <- BK_LG_scores %>% filter(Range == "5")
cor.test_5 <-cor.test(BK_LG_scores_5$GminusL, BK_LG_scores_5$total_bk_bias, method = "pearson")
#= 0.2555
report(cor.test_5)

cor_plot <-  ggplot(BK_LG_scores, aes(GminusL, total_bk_bias))
cor_plot + geom_point() +
  theme_light()+
  #ylim(-0.50,0.50)+
  geom_smooth(method='lm')+
  facet_wrap("Range")+
  ylab("BK bias in expected direction")+
  xlab("<- local bias, global bias ->")+
  theme(strip.background =element_rect(fill="white"))+
  theme(strip.text = element_text(colour = 'black'))

```
#confound analysis
```{r}
all_files_c <- list.files("LG tidy csv/confound")
first_file <- TRUE

#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files_c)){
  if(grepl("b",all_files_c[i])){
    print(all_files_c[i])
    if(first_file){
      LG_data_df_c <- read.csv(paste0("LG tidy csv/confound/",all_files_c[i]))
      LG_data_df_c <- LG_data_df_c %>% mutate(ID = substr(all_files_c[i],1,6))
      first_file <- FALSE
    }
    else{
      LGnew_data_df_c <- read.csv(paste0("LG tidy csv/confound/",all_files_c[i]))
      LGnew_data_df_c <- LGnew_data_df_c %>% mutate(ID = substr(all_files_c[i],1,6))
      LG_data_df_c <- rbind(LG_data_df_c,LGnew_data_df_c)
    }
  }
}

unique(LG_data_df_c$ID) #36
```

#confound df
```{r}
#age table
LG_c_ages <- read_excel("lg_confound_ages.xlsx")
#full_join to combine
LG_data_df_combined_c <- full_join(LG_data_df_c,target_table, by="image_ID_targets")
LG_data_df_combined_c <- full_join(LG_data_df_combined_c,pairs_table, by="image_ID_pairs")
LG_data_df_combined_c <- full_join(LG_data_df_combined_c,LG_c_ages, by="ID")

#if the the global choice is on the left and they make the "z" response, then put G in the choice column, etc
LG_data_df_combined_bias_c <- LG_data_df_combined_c %>% mutate(choice = ifelse(response_pairs == left_key &
                                                                             target_global == pair_left_global,
                                                                           "global", 
                                                                           ifelse(response_pairs == left_key &
                                                                                    target_local == pair_left_local,
                                                                                  "local",
                                                                                  ifelse(response_pairs == right_key &
                                                                                           target_global == pair_right_global,
                                                                                         "global",
                                                                                         ifelse(response_pairs == right_key &
                                                                                                  target_local == pair_right_local,
                                                                                                "local",
                                                                                                NA)))))
```

#calculate bias
```{r}
#for null responses, remove from total n(trials)
LG_data_df_combined_bias_c <- LG_data_df_combined_bias_c %>% mutate(choice_number = ifelse(choice == "global", 1, 0)) %>% filter(!is.na(choice)) 

LG_confound_global_bias <- LG_data_df_combined_bias_c %>% group_by(ID,Range,target_confound) %>% 
                          summarise(global_bias = sum(choice_number)/n())

```

#t.testing analysis 

```{r}
#what is the difference between confound trials or non confound trials participants? within
# independent sample t-test (2 groups, within participants)
six <- LG_confound_global_bias %>% filter(Range == "6 to 8")
res1 <- t.test(global_bias ~ target_confound, data = six)
# Printing the results
res1 #results are nonsignificant, p = 0.9

adult <- six <- LG_confound_global_bias %>% filter(Range == "Adult")
res1 <- t.test(global_bias ~ target_confound, data = adult)
# Printing the results
res1 #results are nonsignificant, p = 0.9935


#is there a significant difference between within participants(within t test), and also between the non-confound
#trials in people who did and did not see the confound (between subjects t test)
#get a measure for each within, then compare that across participants as well 

#this has M and SD for boas for confounded and nonconfounded
LG_confound_grouped <- LG_confound_global_bias   %>%
  group_by(target_confound, Range) %>%
  summarise(mean_bias = mean(global_bias),
            sd_bias = sd(global_bias),
            se_bias=sd_bias/sqrt(n()))
```
#confound diff between experiments
```{r}
#need one column for ID, one for is the participant a confound one or not, and one for global bias
#make confound df first
LG_confound_average_gb <- LG_data_df_combined_bias_c %>% group_by(ID, Range) %>% 
                          summarise(global_bias = sum(choice_number)/n()) %>% mutate(type = 1)
#now the regular ones, first half of adults up to bld149
LG_average_gb <- LG_data_df_combined_bias %>% group_by(ID, Range) %>% 
                          summarise(global_bias = sum(choice_number)/n()) %>% filter(Range %in% c("6 to 8", "Adult")) %>%
                          mutate(type = 0)

LG_con_and_noncon <- rbind(LG_confound_average_gb,LG_average_gb)
unique(LG_con_and_noncon$ID)

#does age range or if you saw the confound trials or not 
con_mod <- aov(global_bias ~ Range*type, data = LG_con_and_noncon)
summary(con_mod)
Anova(con_mod)


#This is a wald chisquare test
#aov is anova
 
```

#adding in the datasets from the confound study to check the development of LG bias and correlation

```{r}
#create new LG dataset: rbind LG_data_df_combined_bias and LG_data_df_combined_bias_c but with the confound trials taken out
LG_confound_no_confound <- LG_data_df_combined_bias_c %>% filter(!target_confound == 1)
LG_combined_df <- rbind(LG_data_df_combined_bias, LG_confound_no_confound)

LG_count_c <-LG_combined_df %>% group_by(ID,Range) %>% count(choice)
LG_count_c <- LG_count_c %>% pivot_wider(names_from = choice, values_from = n) %>% mutate_all(~replace(., is.na(.), 0))
#new column with local-global
LG_combined_gminusl <- LG_count_c %>% mutate(GminusL = global-local) %>% mutate(LG_group = ifelse(GminusL >0, "global", "local"))


#now do the same analyses
#to count choice bias and see how many participants are in each age range
LG_combined_bias <- LG_combined_df %>% group_by(ID,Range) %>% 
                                    summarise(global_bias = sum(choice_number)/n()) %>% 
                                    group_by(Range) %>%
                                    summarize(mean_bias = mean(global_bias),
                                    sd_bias = sd(global_bias),
                                    se_bias=sd_bias/sqrt(n()),
                                    N=n()) %>% ungroup()

#average values!! average of GminusL for each age range################
LG_c_weighted_avg <- LG_combined_gminusl %>% group_by(ID,Range) %>%
                                      summarise(GminusL = mean(GminusL)) %>%
                                    ungroup() %>%
                                    group_by(Range) %>%
                                    summarise(avg_bias = mean(GminusL),
                                              sd_bias = sd(GminusL, na.rm = TRUE),
                                              se_bias=sd_bias/sqrt(n()), 
                                              N = n()) %>% ungroup()

#calculating the points that go on the graph
LG_combined_points <- LG_combined_gminusl  %>% group_by(ID,Range) %>%
                        mutate(bias_round = round_any(GminusL,5)) %>%  ungroup() %>%
                        group_by(Range,bias_round) %>%
                        summarise(Count = length(unique(ID)))


```

#graphing
```{r}
LG_combined_plot <-ggplot() +
  geom_col(LG_c_weighted_avg, mapping = aes(x = Range, y = avg_bias), color = "black", fill = NA) +
  geom_col(LG_c_weighted_avg, mapping = aes(x = Range, y = avg_bias, fill = Range), alpha = 0.5) +
  geom_errorbar(LG_c_weighted_avg, mapping = aes(x = Range, y = avg_bias, ymin = avg_bias-se_bias,
                                              ymax = avg_bias+se_bias), alpha = 1, width = .75) +
  geom_jitter(LG_combined_gminusl, mapping = aes(x = Range, y = GminusL)) +
  theme_light() +
  ylab("Global Bias") +
  #scale_color_manual(values = rev(cols)) +
  #scale_fill_manual(values = rev(cols)) +
  xlab("global and local groups in each age range") +
  ylab("<- local bias, global bias ->")

LG_combined_plot
```
#combined df analyses
```{r}
#LG_bias_poirel_one_row
lgm2 <- glm(GminusL ~ 0 + Range, data = LG_combined_gminusl)
summary(lgm2)
Anova(lgm2)
# none are different from zero


#are they different from each other? no
contrast(emmeans(lgm2, ~ Range) , method = "pairwise", type = "response")

#lg_bias_table <-summary.glm(m1)$coefficients
#write.csv(bko1_bias_table, "significance tables/bko1_bias_table.csv")

#t testing each of the 4 age groups from 0
LG_combined_gminusl %>% group_by(Range) %>%
                       summarise(t_val = t.test(GminusL, mu = 0)$statistic,
                                 df = t.test(GminusL, mu = 0)$parameter,
                                 p_val = t.test(GminusL, mu = 0)$p.value)

res <- t.test(LG_combined_gminusl$GminusL, mu = 0)
# Printing the results: significantly different from zero
res

```



