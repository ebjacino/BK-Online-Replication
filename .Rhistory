}
all_files <- list.files("LG CSV files Looped")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("bk",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("LG CSV files Looped/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("LG CSV files Looped/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
all_files <- list.files("LG CSV files Looped")
library(dplyr)
all_files <- list.files("LG CSV files Looped")
knitr::opts_chunk$set(echo = TRUE)
round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}
angular_color = "#E01A4F"
curved_color = "#FFC05C"
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(scales)
all_files <- list.files("LG CSV files Looped") #79 items 5/12/22
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("bk",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("LG CSV files Looped/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("LG CSV files Looped/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
unique(all_data_df$ID) #79 IDs
#filter out the NAs
all_data_df <- all_data_df %>% filter(!is.na(correct))
all_data_df <- all_data_df %>% mutate(group = ifelse(substr(ID,4,4)=="1","adult","child"))
#CALCULATE CHOICE BIAS
data_2_sounds <- all_data_df %>% group_by(ID,sound,group) %>%
summarise(bias = sum(correct)/n())
#85 files 5/18
library(dplyr)
library(tidyverse)
library(emmeans)
#add in age data
BKLG_ages <- read.csv("BKLG ages.csv")
unique(BKLG_ages$Range)
BKLG_ages <- BKLG_ages %>% mutate(ID = tolower(ID)) %>% select(ID,Age,Range)
#data_2_sounds
df_2sounds_age <- full_join(data_2_sounds,BKLG_ages, by="ID")
all_data_df_age <- full_join(all_data_df,BKLG_ages, by="ID") %>% drop_na()
unique(all_data_df_age$ID)
all_data_df_age2 <- all_data_df_age %>% drop_na() %>%
group_by(ID, Range,sound) %>%
mutate(bias = sum(correct)/n() - 0.5)
#pivot_data_2_sounds <- data_2_sounds %>% pivot_wider(names_from = sound, values_from = bias, values_fill = NA)
#pivot_data_2_sounds
age_bias_data <- all_data_df_age %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
group_by(ID,Range,sound) %>%
summarise(bias = sum(correct)/n() - 0.5) %>%
mutate(bias = ifelse(sound == "spiky",-1*bias,bias)) %>%
group_by(Range,sound) %>%
summarize(mean_bias = mean(bias),
sd_bias = sd(bias),
se_bias=sd_bias/sqrt(n()),
N=n()) %>%
ungroup() #%>%
#mutate(stimulus = fct_reorder2(stimulus, sound, mean_bias))
age_bias_data_points <- all_data_df_age %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
group_by(ID,Range,sound) %>%
summarise(bias = sum(correct)/n() - 0.5) %>%
ungroup() %>%
mutate(bias = ifelse(sound == "spiky",-1*bias,bias)) %>%
mutate(bias_round = round_any(bias,0.25)) %>%
group_by(Range,sound,bias_round) %>%
summarise(Count = n())
cols <- hue_pal()(2)
age_plot <-ggplot() +
geom_col(age_bias_data, mapping = aes(x = sound, y = mean_bias), color = "black", fill = NA) +
geom_point(age_bias_data_points, mapping = aes(x = sound, y = bias_round, size = Count, color = sound)) +
geom_col(age_bias_data, mapping = aes(x = sound, y = mean_bias, fill = sound), alpha = 0.5) +
geom_point(age_bias_data, mapping = aes(x = sound, y = mean_bias)) +
geom_errorbar(age_bias_data, mapping = aes(x = sound, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1) +
theme_classic() +
facet_wrap("Range") +
ylim(-0.5,0.5) +
ylab("Bias") +
scale_color_manual(values = rev(cols)) +
scale_fill_manual(values = rev(cols)) +
# scale_fill_manual(values = c(angular_color,curved_color)) +
#scale_color_manual(values = c(angular_color,curved_color)) +
xlab("Sound")
age_plot
ggsave("graphs/presentation graphs/6-8_age_plot_bko1.png", width = 6, height = 4)
summary(m)
m <- glm(bias ~ 0+Range:sound, data = all_data_df_age2)
summary(m)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(forcats)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
angular_color = "#FFA69E"
curved_color = "#B88BBB"
round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}
all_data_df <- read.csv("all_data_df.csv")
stimulus_bias_data <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
group_by(ID,stimulus,sound) %>%
summarise(bias = sum(correct)/n() - 0.5) %>%
mutate(bias = ifelse(sound == "angular",-1*bias,bias)) %>%
group_by(stimulus,sound) %>%
summarize(mean_bias = mean(bias),
sd_bias = sd(bias),
se_bias=sd_bias/sqrt(n())) %>%
ungroup() %>%
mutate(stimulus = fct_reorder2(stimulus, sound, mean_bias))
stimulus_bias_data_points <- all_data_df %>% mutate(stimulus = toupper(sub(".wav","",sub("sound/","",stimulus)))) %>%
group_by(ID,stimulus,sound) %>%
summarise(bias = sum(correct)/n() - 0.5) %>%
ungroup() %>%
mutate(bias = ifelse(sound == "angular",-1*bias,bias)) %>%
mutate(bias_round = round_any(bias,0.25)) %>%
group_by(stimulus,sound,bias_round) %>%
summarise(Count = n())
ggplot() +
geom_col(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias), color = "black", fill = NA) +
geom_point(stimulus_bias_data_points, mapping = aes(x = stimulus, y = bias_round, size = Count, color = sound)) +
geom_col(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias, fill = sound), alpha = 0.5) +
geom_point(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias)) +
geom_errorbar(stimulus_bias_data, mapping = aes(x = stimulus, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1) +
theme_classic() +
ylim(-0.5,0.5) +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
ylab("Bias") +
xlab("Stimulus")
#ggsave("poster graphs/all_stim_graph.png")
#CALCULATE CHOICE BIAS
#group_by(ID,sound,group) group for when i have both adults and children
data_orth <- all_data_df %>% group_by(ID,sound) %>%
summarise(bias = sum(correct)/n())
data_all_sounds <- all_data_df %>% group_by(ID,sound,stimulus) %>%
summarise(bias = sum(correct)/n())
data_vowel_type <- all_data_df %>% group_by(vowel_type, ID) %>%
summarise(bias = sum(correct)/n())
data_congruency = all_data_df %>% group_by(congruent, ID) %>%
summarise(bias = sum(correct)/n())
data_voicing = all_data_df %>% group_by(voicing, ID) %>%
summarise(bias = sum(correct)/n())
data_consonant = all_data_df %>% group_by(consonant_type, ID) %>%
summarise(bias = sum(correct)/n())
#listing comparisons for significance bars
#bias for orthography
orth_comparisons <- list( c("angular", "curved"))
#bias for vowel type
vowel_comparisions <- list( c("/a/", "/i/"))
#bias for congruency
congruency_comparisions <- list( c("congruent", "incongruent"))
#bias for voicing
voicing_comparisions <- list( c("unvoiced", "voiced"))
#bias for consonant type
consonant_comparisons <- list( c("stop", "fricative"),
c("fricative", "sonorant"),
c("stop", "sonorant"))
View(all_data_df)
all_files <- list.files("bko2_CSVs/")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("bko2_csv_kid/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("bko2_csv_kid/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
all_files <- list.files("bko2_CSVs")
library(dplyr)
all_files <- list.files("bko2_CSVs")
library(dplyr)
all_files <- list.files("bko2_CSVs")
all_files <- list.files("bko2_CSVs")
all_files <- list.files("bko2_CSVs/")
first_file <- TRUE
all_files <- list.files("bko2_CSVs/")
all_files <- list.files("/bko2_CSVs")
all_files <- list.files("bko2_CSVs")
all_files <- list.files("bko2_CSVs")
library(dplyr)
all_files <- list.files("bko2_CSVs")
all_files <- list.files("LG CSV files Looped") #79 items 5/12/22
all_files <- list.files("bko2_CSVs")
all_files <- list.files("bko2_CSVs")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("bko2_CSVs/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("bko2_CSVs/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
all_files <- list.files("/Users/Elisabeth/Desktop/UMASS/BKonline data/BK online replication/bko2_CSVs")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("bko2_CSVs/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("bko2_CSVs/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
all_files <- list.files("/Users/Elisabeth/Desktop/UMASS/BKonline data/BK online replication/bko2_CSVs")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("bko2_CSVs/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("bko2_CSVs/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
?count()
setwd("~/Desktop/UMASS/BKonline data/BK-Online-Replication")
library(dplyr)
library(stringr)
library(tidyverse)
correct_stim_list = c("sound/baba_rep.wav" = "bouba",
"sound/gaga_rep.wav" = "bouba",
"sound/keekee.wav" = "kiki",
"sound/teetee.wav" = "kiki")
left_key = "z"
right_key = "m"
which_is_correct <- function(stimuli,lefts,rights) {
#Make a new vector the same length as the number of rows
correct_vec <- rep(NA,length(stimuli))
#For each row in the dataset....
for(i in seq(1:length(stimuli))){
#Get the correct type ("Bouba" or "Kiki") by checking in the stim list
correct_type <- correct_stim_list[stimuli[i]]
#If the correct type is in the left one the correct key was the left key
if(grepl(correct_type, lefts[i], fixed = TRUE)){
correct_key <- left_key
}
#If the correct type is in the right one the correct key was the right key
else if(grepl(correct_type, rights[i], fixed = TRUE)){
correct_key <- right_key
}
#If it isn't in either something has gone wrong so you'll get an NA
else{
correct_key <- NA
}
#Put that correct key in the output vector
correct_vec[i] <- correct_key
}
#Return the final filled in vector
return(correct_vec)
}
#look at the results files
rds_files <- list.files("LG_double_image_RDS",
pattern = "\\.rds$",
full.names = TRUE)
rds_files
for(file in rds_files){
print(file)
file_id <- str_extract(file,"b[kl]g\\d\\d\\d")
data <- readRDS(file)
#assign ID
participant_ID <- data$results$`sp_id`[[1]]
main_data <- data$results$`Main page`[[1]]
df <- read.table(text = main_data, sep =",", header = TRUE, stringsAsFactors = FALSE)
#df is the raw data, tells you stimulus and responses
##Ben Code Attempt***creating tidy data and choice bias score***
#First remove unneeded columns
data_cols <- df %>% select(c(trial_type,stimulus,response,left_image,right_image,correct_response,correct))
#Then Filter practice and experimental trials
data_prac <- data_cols %>% filter(grepl("Prac", stimulus, fixed = TRUE))
data_exp <- data_cols %>% filter(!grepl("Prac", stimulus, fixed = TRUE)) %>%
filter(trial_type  %in% c("bouba-kiki","image-keyboard-response")) %>%
filter(stimulus != "img/fixation.png")
#filter out BK data
data_exp_bk <-data_exp %>% filter(trial_type == "bouba-kiki")
#filter out the LG data
data_exp_lg <-data_exp %>% filter(trial_type =="image-keyboard-response") %>%
select(c(trial_type, stimulus, response))
#Now write a function to find if the left or the right image is "correct"
data_exp_bk <- data_exp_bk %>% mutate(correct_response = which_is_correct(stimulus,left_image,right_image))
data_exp_bk <- data_exp_bk %>% mutate(correct = ifelse(correct_response == response,
1,
ifelse(response == left_key | response == right_key,
0,
NA)))
data_exp_bk <- data_exp_bk %>% mutate(sound = ifelse(stimulus %in% c("sound/baba_rep.wav","sound/gaga_rep.wav"),
"round",
ifelse(stimulus %in% c("sound/teetee.wav","sound/keekee.wav"),
"spiky",
NA))) %>%
filter(!is.na(correct))
#adding columns to LG files to do analysis ############
data_exp_lg <- data_exp_lg %>% separate(stimulus, c("type","image_ID"), sep = "/")
data_exp_lg <- data_exp_lg %>% group_by(type) %>%
mutate(trial_num = row_number()) %>%
ungroup() %>%
pivot_wider(names_from = type, values_from = c(image_ID,response)) %>%
select(!c(trial_type,response_targets))
file_path_bk <- paste0("LG CSV files Looped/",file_id,"_bk.csv")
file_path_lg <- paste0("LG tidy csv/",file_id,"_lg.csv")
file_path_prac <- paste0("LG practice trials/",file_id,".csv")
#write.csv(data_prac, file_path_prac)
#write.csv(data_exp_bk, file_path_bk)
write.csv(data_exp_lg, file_path_lg)
}
library(dplyr)
library(readxl)
library("writexl")
library(ggplot2)
library(ggpubr)
round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}
all_files <- list.files("LG tidy csv")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
LG_data_df <- read.csv(paste0("LG tidy csv/",all_files[i]))
LG_data_df <- LG_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
LGnew_data_df <- read.csv(paste0("LG tidy csv/",all_files[i]))
LGnew_data_df <- LGnew_data_df %>% mutate(ID = substr(all_files[i],1,6))
LG_data_df <- rbind(LG_data_df,LGnew_data_df)
}
}
}
#load in the tables of targets and pairs descriptions
target_table <- read_excel("LG_target_table.xlsx")
pairs_table <- read_excel("LG_pair_table.xlsx")
age_table <- read_excel("LG_ages.xlsx")
age_table <- age_table %>% mutate(ID = tolower(ID)) #%>% select(ID,Age,Range)
#full_join to combine
LG_data_df_combined <- full_join(LG_data_df,target_table, by="image_ID_targets")
LG_data_df_combined <- full_join(LG_data_df_combined,pairs_table, by="image_ID_pairs")
LG_data_df_combined <- full_join(LG_data_df_combined,age_table, by="ID")
View(LG_data_df_combined)
#full_join to combine
LG_data_df_combined <- full_join(LG_data_df,target_table, by="image_ID_targets")
LG_data_df_combined <- full_join(LG_data_df_combined,pairs_table, by="image_ID_pairs")
LG_data_df_combined <- full_join(LG_data_df_combined,age_table, by="ID")
#if the the global choice is on the left and they make the "z" response, then put G in the choice column, etc
LG_data_df_combined_bias <- LG_data_df_combined %>% mutate(choice = ifelse(response_pairs == left_key &
target_global == pair_left_global,
"global",
ifelse(response_pairs == left_key &
target_local == pair_left_local,
"local",
ifelse(response_pairs == right_key &
target_global == pair_right_global,
"global",
ifelse(response_pairs == right_key &
target_local == pair_right_local,
"local",
NA)))))
View(LG_data_df_combined_bias)
#calculate global bias: n(global)/n() ################
#for null responses, remove from total n(trials)
LG_data_df_combined_bias <- LG_data_df_combined_bias %>% mutate(choice_number = ifelse(choice == "global", 1, 0)) %>%
filter(!is.na(choice))
LG_bias_ind <- LG_data_df_combined_bias %>% group_by(ID) %>% summarise(global_bias = sum(choice_number)/n())
View(LG_bias_ind)
LG_bias_data <- LG_data_df_combined_bias %>% group_by(ID,Range) %>%
summarise(global_bias = sum(choice_number)/n()) %>%
group_by(Range) %>%
summarize(mean_bias = mean(global_bias),
sd_bias = sd(global_bias),
se_bias=sd_bias/sqrt(n()),
N=n()) %>% ungroup()
View(LG_bias_data)
all_files <- list.files("LG tidy csv")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
LG_data_df <- read.csv(paste0("LG tidy csv/",all_files[i]))
LG_data_df <- LG_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
LGnew_data_df <- read.csv(paste0("LG tidy csv/",all_files[i]))
LGnew_data_df <- LGnew_data_df %>% mutate(ID = substr(all_files[i],1,6))
LG_data_df <- rbind(LG_data_df,LGnew_data_df)
}
}
}
#load in the tables of targets and pairs descriptions
target_table <- read_excel("LG_target_table.xlsx")
pairs_table <- read_excel("LG_pair_table.xlsx")
age_table <- read_excel("LG_ages.xlsx")
age_table <- age_table %>% mutate(ID = tolower(ID)) #%>% select(ID,Age,Range)
#full_join to combine
LG_data_df_combined <- full_join(LG_data_df,target_table, by="image_ID_targets")
LG_data_df_combined <- full_join(LG_data_df_combined,pairs_table, by="image_ID_pairs")
LG_data_df_combined <- full_join(LG_data_df_combined,age_table, by="ID")
#if the the global choice is on the left and they make the "z" response, then put G in the choice column, etc
LG_data_df_combined_bias <- LG_data_df_combined %>% mutate(choice = ifelse(response_pairs == left_key &
target_global == pair_left_global,
"global",
ifelse(response_pairs == left_key &
target_local == pair_left_local,
"local",
ifelse(response_pairs == right_key &
target_global == pair_right_global,
"global",
ifelse(response_pairs == right_key &
target_local == pair_right_local,
"local",
NA)))))
#calculate global bias: n(global)/n() ################
#for null responses, remove from total n(trials)
LG_data_df_combined_bias <- LG_data_df_combined_bias %>% mutate(choice_number = ifelse(choice == "global", 1, 0)) %>%
filter(!is.na(choice))
LG_bias_ind <- LG_data_df_combined_bias %>% group_by(ID) %>% summarise(global_bias = sum(choice_number)/n())
View(LG_bias_ind)
LG_bias_data <- LG_data_df_combined_bias %>% group_by(ID,Range) %>%
summarise(global_bias = sum(choice_number)/n()) %>%
group_by(Range) %>%
summarize(mean_bias = mean(global_bias),
sd_bias = sd(global_bias),
se_bias=sd_bias/sqrt(n()),
N=n()) %>% ungroup()
LG_bias_data_points <- LG_data_df_combined_bias  %>% group_by(ID,Range) %>%
summarise(global_bias = sum(choice_number)/n()) %>%
ungroup() %>%
mutate(bias_round = round_any(global_bias,0.25)) %>%
group_by(Range,bias_round) %>%
summarise(Count = n())
View(LG_bias_data)
View(LG_bias_data_points)
#GRAPH TIME
LG_bias_plot <-ggplot() +
geom_col(LG_bias_data, mapping = aes(x = Range, y = mean_bias), color = "black", fill = NA) +
geom_point(LG_bias_data_points, mapping = aes(x = Range, y = bias_round, size = Count, color = Range)) +
geom_col(LG_bias_data, mapping = aes(x = Range, y = mean_bias, fill = Range), alpha = 0.5) +
geom_point(LG_bias_data, mapping = aes(x = Range, y = mean_bias)) +
geom_errorbar(LG_bias_data, mapping = aes(x = Range, y = mean_bias, ymin = mean_bias-se_bias, ymax = mean_bias+se_bias), alpha = 1) +
theme_classic() +
#facet_wrap("Range") +
#ylim(-0.5,0.5) +
ylab("Global Bias") +
#scale_color_manual(values = rev(cols)) +
#scale_fill_manual(values = rev(cols)) +
xlab("Age")
LG_bias_plot
#isolate the participants with confound trials
LG_confound_trials <- LG_data_df_combined_bias %>% mutate(confound_participant = ifelse(ID %in% c("blg166", "blg167",
"blg168", "blg169",
"blg170"), 1, 0))
#calculate global bias for confound trials and normal trials
LG_confound_trials <- LG_confound_trials %>% filter(confound_participant == 1) %>%
group_by(ID, target_confound) %>%
summarise(global_bias = sum(choice_number)/n())
View(LG_confound_trials)
View(LG_confound_trials)
