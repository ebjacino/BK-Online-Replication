sum_table <- all_data_df %>% group_by(Range,Sex,ID) %>%
summarise(bias = sum(shape_choice)/n()- 0.5,
N = n())
one_row <- all_data_df %>% group_by(ID) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
View(one_row)
one_row <- all_data_df %>% group_by(ID,Range,Sex,Bilingual) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
View(one_row)
sum_table <- one_row %>% count(one_row$Sex == "F")
View(sum_table)
sum_table <- one_row %>% summarise(count =count(one_row$Sex == "F"))
sum_table <- one_row %>% group_by(Range) %>% count(Sex)
View(sum_table)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(lme4)
library(ggpubr)
library(forcats)
library(emmeans)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)     #to read excel files
demo_df <- read_excel("master demographics log edited.xlsx")
#Get rid of any rows with NA in them (blank or incomplete data) in the "Experiment Run" column
demo_df <- demo_df %>% drop_na("Experiment_Run")
demo_df_bko2 <- demo_df %>% filter(Experiment_Run =="BKO2")
#filter out some extra participants we don't need. Take out the 2 participants we need to exclude.
demo_df_bko2 <- demo_df_bko2 %>% mutate(Include_Exclude = ifelse(is.na(Include_Exclude), "Include", "Exclude")) %>%
filter(Include_Exclude != "Exclude") %>%
mutate(Bilingual = ifelse(Bilingual == "yes",1,0))
all_data_df <- read_excel("bko2 all trials df.xlsx")
all_data_df <- full_join(all_data_df,demo_df_bko2, by="ID")
one_row <- all_data_df %>% group_by(ID,Range,Sex,Bilingual) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
sum_table <- one_row %>% group_by(Range) %>% count(Sex)
sum_table <- one_row %>% group_by(Range) %>% count(Sex,Bilingual)
sum_table_sex <- one_row %>% group_by(Range) %>% count(Sex)
sum_table_sex <- one_row %>% group_by(Range) %>% count(Sex)
View(sum_table_sex)
sum_table_bilingual <-one_row %>% group_by(Range) %>% count(Bilingual)
View(sum_table_bilingual)
sum_table_race <-one_row %>% group_by(Range) %>% count(Race)
View(one_row)
View(all_data_df)
glm_sex <- glmer(shape_choice ~ Sex + (1|ID), data = all_data_df, family = "binomial")
summary(glm_sex)
glm_bilingual <- glmer(shape_choice ~ Bilingual + (1|ID), data = all_data_df, family = "binomial")
Anova(glm_sex)
summary(glm_bilingual)
anova(glm_bilingual)
anova(glm_sex)
Anova(glm_sex)
anova(glm_sex)
glm_bilingual <- glmer(shape_choice ~ Bilingual + (1|ID), data = all_data_df, family = "binomial")
summary(glm_bilingual)
anova(glm_bilingual)
anova(glm_sex)
Anova(glm_sex)
Anova(glm_bilingual)
summary(glm_sex)
#sex
glm_sex <- glmer(WJ_score ~ Sex + (1|ID), data = all_data_df, family = "binomial")
#sex
glm_sex <- glmer(WJ_score ~ Sex + (1|ID), data = all_data_df)
Anova(glm_sex)
#bilingualism
glm_bilingual <- glmer(WJ_score ~ Bilingual + (1|ID), data = all_data_df)
#bilingualism
glm_bilingual <- lmer(WJ_score ~ Bilingual + (1|ID), data = all_data_df)
#bilingualism
glm_bilingual <- aov(WJ_score ~ Bilingual + (1|ID), data = all_data_df)
Anova(glm_bilingual)
#sex
glm_sex <- glmer(WJ_score ~ Sex + (1|ID), data = all_data_df)
#sex
glm_sex <- lmer(WJ_score ~ Sex + (1|ID), data = all_data_df)
#sex
glm_sex <- lmer(WJ_score ~ Sex + (1|ID), data = all_data_df)
#bilingualism
glm_bilingual <- lmer(WJ_score ~ Bilingual + (1|ID), data = all_data_df)
#bilingualism
glm_bilingual <- glmer(WJ_score ~ Bilingual + (1|ID), data = all_data_df, family = "binomial")
#bilingualism
glm_bilingual <- lmer(WJ_score ~ Bilingual + (1|ID), data = all_data_df)
#sex
glm_sex <- lmer(WJ_score ~ Sex + (1|ID), data = all_data_df, family = "poisson")
#sex
glm_sex <- glmer(WJ_score ~ Sex + (1|ID), data = all_data_df, family="poisson")
Anova(glm_sex)
#bilingualism
glm_bilingual <- lmer(WJ_score ~ Bilingual + (1|ID), data = all_data_df, family="poisson")
#bilingualism
glm_bilingual <- glmer(WJ_score ~ Bilingual + (1|ID), data = all_data_df, family="poisson")
Anova(glm_bilingual)
#race
glm_race <- glmer(WJ_score ~ Race + (1|ID), data = all_data_df, family="poisson")
Anova(glm_race)
#race
glm_race <- glmer(shape_choice ~ Race + (1|ID), data = all_data_df, family="poisson")
#race
glm_race <- glmer(shape_choice ~ Race + (1|ID), data = all_data_df, family="binomial")
Anova(glm_race)
sum_table_race <- one_row %>% group_by(Range) %>% count(Race)
one_row <- all_data_df %>% group_by(ID,Range,Sex,Bilingual,Race) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
#sum tables
sum_table_sex <- one_row %>% group_by(Range) %>% count(Sex)
sum_table_bilingual <-one_row %>% group_by(Range) %>% count(Bilingual)
View(sum_table_bilingual)
sum_table_race <- one_row %>% group_by(Range) %>% count(Race)
View(sum_table_race)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(lme4)
library(ggpubr)
library(forcats)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)     #to read excel files
demo_df <- read_excel("master demographics log edited.xlsx")
#Get rid of any rows with NA in them (blank or incomplete data) in the "Experiment Run" column
demo_df <- demo_df %>% drop_na("Experiment_Run")
demo_df_bko2 <- demo_df %>% filter(Experiment_Run =="BKO2")
#filter out some extra participants we don't need. Take out the 2 participants we need to exclude.
demo_df_bko2 <- demo_df_bko2 %>% mutate(Include_Exclude = ifelse(is.na(Include_Exclude), "Include", "Exclude")) %>%
filter(Include_Exclude != "Exclude") %>%
mutate(Bilingual = ifelse(Bilingual == "yes",1,0))
all_data_df <- read_excel("bko2 all trials df.xlsx")
all_data_df <- full_join(all_data_df,demo_df_bko2, by="ID")
one_row <- all_data_df %>% group_by(ID,Range,Sex,Bilingual,Race) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
#sum tables
sum_table_sex <- one_row %>% group_by(Range) %>% count(Sex)
View(sum_table_sex)
sum_table_bilingual <-one_row %>% group_by(Range) %>% count(Bilingual)
sum_table_race <- one_row %>% group_by(Range) %>% count(Race)
View(sum_table_race)
sum_table_race_simple <- one_row %>% mutate(Race = ifelse(Race == "White", "White", "nonWhite"))
View(sum_table_race_simple)
sum_table_race_simple <- one_row %>% mutate(Race = ifelse(Race == "White", "White", "nonWhite")) %>%
group_by(Range) %>% count(Race)
#race
#for race analysis, change to either "white" or "nonwhite"
all_data_df_racesimple <- all_data_df %>% mutate(Race = ifelse(Race == "White", "White", "nonWhite"))
View(all_data_df_racesimple)
glm_race <- glmer(WJ_score ~ Race + (1|ID), data = all_data_df_racesimple, family="poisson")
Anova(glm_race)
#race
glm_race <- glmer(WJ_score ~ Race + (1|ID), data = all_data_df_racesimple, family="poisson")
Anova(glm_race)
all_data_df_location <- all_data_df %>% mutate(Lround_or_spiky_shape = ifelse(grepl("bouba", left_image), "round", "spiky"))
View(all_data_df_location)
glm_location <- glmer(shape_choice ~ left_image*Lround_or_spiky_shape + (1|ID), data = all_data_df_location, family="binomial")
glm_location <- glmer(shape_choice ~ left_image+Lround_or_spiky_shape + (1|ID), data = all_data_df_location, family="binomial")
glm_location <- glmer(shape_choice ~ left_image*Lround_or_spiky_shape + (1|ID), data = all_data_df_location, family="binomial")
Anova(glm_location)
glm_location <- glmer(shape_choice ~ left_image*Lround_or_spiky_shape + (1|ID), data = all_data_df_location, family="binomial")
glm_location <- glmer(shape_choice ~ left_image + (1|ID), data = all_data_df_location, family="binomial")
Anova(glm_location)
glm_location <- glmer(shape_choice ~ left_image*Lround_or_spiky_shape + (1|ID), data = all_data_df_location, family="binomial")
Anova(glm_location)
glm_location <- glmer(shape_choice ~ left_image + (1|ID), data = all_data_df_location, family="binomial")
Anova(glm_location)
glm_location <- glmer(shape_choice ~ left_image*Lround_or_spiky_shape + (1|ID), data = all_data_df_location, family="binomial")
Anova(glm_location)
glm_location <- glmer(shape_choice ~ left_image*Lround_or_spiky_shape + (1|ID), data = all_data_df_location, family="binomial")
?(pwr)
?pwr()
library(tidyverse)
library(ggplot2)
library(lme4)
library(ggpubr)
library(forcats)
library(emmeans)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)
library("writexl")
library("xlsx")
library(viridis)
library(ppcor) #for partial correlation
library(lpSolve)
library(irr) #for inter-rater reliability
angular_color = "#E01A4F"
curved_color = "#FFC05C"
third_color = "#80B8EF"
congruent_color = "#56B375"
#incongruent_color = "#791E94"
incongruent_color = "#9046CF"
#for the dots on the graphs
round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}
#
data_split_consonant_type = all_data_df %>% group_by(consonant_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
all_files <- list.files("bko2 full paradigm CSVs")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
#filter out the NAs
all_data_df <- all_data_df %>% filter(!is.na(correct))
unique(all_data_df$ID)
left_key = "z"
right_key = "m"
age_table <- read_excel("bko2 age table.xlsx")
all_data_df <- full_join(all_data_df,age_table, by="ID")
WJ_scores <- read_excel("WJ scores.xlsx")
all_data_df <- full_join(all_data_df,WJ_scores, by="ID")
#CALCULATE CHOICE BIAS
#group_by(ID,sound,group) group for when i have both adults and children
all_data_df <- all_data_df %>% mutate(shape_choice = ifelse(grepl("bouba",left_image)  & response == left_key,
1,
ifelse(grepl("bouba",right_image)  & response == right_key, 1,
0)))
#write an excel file for all this with library("xlsx")
#write.xlsx(all_data_df, file = "bko2 all trials df.xlsx")
data_orth <- all_data_df %>% group_by(ID,sound,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_all_sounds <- all_data_df %>% group_by(ID,sound,stimulus) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_vowel_type <- all_data_df %>% group_by(vowel_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_congruency = all_data_df %>% group_by(congruent, ID,Range) %>%
summarise(bias = sum(correct)/n())
data_voicing = all_data_df %>% group_by(voicing, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_consonant = all_data_df %>% group_by(consonant_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
#
data_split_consonant_type = all_data_df %>% group_by(consonant_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
View(data_split_consonant_type)
#df for graphing
consonant_graph_df_split <- data_split_consonant_type %>% group_by(consonant_type,Range) %>%
summarize(mean_bias = mean(bias),
sd_bias = sd(bias),
se_bias=sd_bias/sqrt(n()),
N = n())
View(consonant_graph_df_split)
#by range. is there a difference between bias for consonant_type  for different age ranges?
m_mult_co <- glmer(shape_choice ~ Range*consonant_type + (1|ID), data = all_data_df, family = "binomial")
Anova(m_mult_co)
contrast(emmeans(m_mult_co, ~ Range | consonant_type) , method = "pairwise", type = "response")
library(tidyverse)
library(dplyr)
library(ggplot2)
library(lme4)
library(ggpubr)
library(forcats)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)     #to read excel files
demo_df <- read_excel("master demographics log edited.xlsx")
#Get rid of any rows with NA in them (blank or incomplete data) in the "Experiment Run" column
demo_df <- demo_df %>% drop_na("Experiment_Run")
demo_df_bko2 <- demo_df %>% filter(Experiment_Run =="BKO2")
#filter out some extra participants we don't need. Take out the 2 participants we need to exclude.
demo_df_bko2 <- demo_df_bko2 %>% mutate(Include_Exclude = ifelse(is.na(Include_Exclude), "Include", "Exclude")) %>%
filter(Include_Exclude != "Exclude") %>%
mutate(Bilingual = ifelse(Bilingual == "yes",1,0))
all_data_df <- read_excel("bko2 all trials df.xlsx")
all_data_df <- full_join(all_data_df,demo_df_bko2, by="ID")
one_row <- all_data_df %>% group_by(ID,Range,Sex,Bilingual,Race) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
#sum tables
sum_table_sex <- one_row %>% group_by(Range) %>% count(Sex)
sum_table_bilingual <-one_row %>% group_by(Range) %>% count(Bilingual)
sum_table_race <- one_row %>% group_by(Range) %>% count(Race)
sum_table_race_simple <- one_row %>% mutate(Race = ifelse(Race == "White", "White", "nonWhite")) %>%
group_by(Range) %>% count(Race)
#sex
glm_sex <- glmer(shape_choice ~ Sex + (1|ID), data = all_data_df, family = "binomial")
Anova(glm_sex)
#bilingualism
glm_bilingual <- glmer(shape_choice ~ Bilingual + (1|ID), data = all_data_df, family = "binomial")
Anova(glm_bilingual)
#race
#for race analysis, change to either "white" or "nonwhite"
all_data_df_racesimple <- all_data_df %>% mutate(Race = ifelse(Race == "White", "White", "nonWhite"))
glm_race <- glmer(WJ_score ~ Race + (1|ID), data = all_data_df_racesimple, family="poisson")
Anova(glm_race)
View(glm_bilingual)
View(sum_table_sex)
View(sum_table_bilingual)
View(sum_table_sex)
View(sum_table_race_simple)
library(tidyverse)
library(ggplot2)
library(lme4)
library(ggpubr)
library(forcats)
library(emmeans)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)
library("writexl")
library("xlsx")
library(viridis)
library(ppcor) #for partial correlation
library(lpSolve)
library(irr) #for inter-rater reliability
angular_color = "#E01A4F"
curved_color = "#FFC05C"
third_color = "#80B8EF"
congruent_color = "#56B375"
#incongruent_color = "#791E94"
incongruent_color = "#9046CF"
#for the dots on the graphs
round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}
all_files <- list.files("bko2 full paradigm CSVs")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
#filter out the NAs
all_data_df <- all_data_df %>% filter(!is.na(correct))
unique(all_data_df$ID)
left_key = "z"
right_key = "m"
#
data_split_consonant_type = all_data_df %>% group_by(consonant_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
age_table <- read_excel("bko2 age table.xlsx")
all_data_df <- full_join(all_data_df,age_table, by="ID")
WJ_scores <- read_excel("WJ scores.xlsx")
all_data_df <- full_join(all_data_df,WJ_scores, by="ID")
#CALCULATE CHOICE BIAS
#group_by(ID,sound,group) group for when i have both adults and children
all_data_df <- all_data_df %>% mutate(shape_choice = ifelse(grepl("bouba",left_image)  & response == left_key,
1,
ifelse(grepl("bouba",right_image)  & response == right_key, 1,
0)))
#write an excel file for all this with library("xlsx")
#write.xlsx(all_data_df, file = "bko2 all trials df.xlsx")
data_orth <- all_data_df %>% group_by(ID,sound,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_all_sounds <- all_data_df %>% group_by(ID,sound,stimulus) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_vowel_type <- all_data_df %>% group_by(vowel_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_congruency = all_data_df %>% group_by(congruent, ID,Range) %>%
summarise(bias = sum(correct)/n())
data_voicing = all_data_df %>% group_by(voicing, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_consonant = all_data_df %>% group_by(consonant_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
#
data_split_consonant_type = all_data_df %>% group_by(consonant_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
View(data_split_consonant_type)
#df for graphing
consonant_graph_df_split <- data_split_consonant_type %>% group_by(consonant_type,Range) %>%
summarize(mean_bias = mean(bias),
sd_bias = sd(bias),
se_bias=sd_bias/sqrt(n()),
N = n())
View(consonant_graph_df_split)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(lme4)
library(ggpubr)
library(forcats)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)     #to read excel files
demo_df <- read_excel("master demographics log edited.xlsx")
#Get rid of any rows with NA in them (blank or incomplete data) in the "Experiment Run" column
demo_df <- demo_df %>% drop_na("Experiment_Run")
demo_df_bko2 <- demo_df %>% filter(Experiment_Run =="BKO2")
#filter out some extra participants we don't need. Take out the 2 participants we need to exclude.
demo_df_bko2 <- demo_df_bko2 %>% mutate(Include_Exclude = ifelse(is.na(Include_Exclude), "Include", "Exclude")) %>%
filter(Include_Exclude != "Exclude") %>%
mutate(Bilingual = ifelse(Bilingual == "yes",1,0))
all_data_df <- read_excel("bko2 all trials df.xlsx")
all_data_df <- full_join(all_data_df,demo_df_bko2, by="ID")
#shape_choice is the proportion of times participants choose a round shape. this is our choice bias measure.
one_row <- all_data_df %>% group_by(ID,Range,Sex,Bilingual,Race) %>%
summarise(bias = sum(shape_choice)/n()- 0.5)
#sum tables
sum_table_sex <- one_row %>% group_by(Range) %>% count(Sex)
sum_table_bilingual <-one_row %>% group_by(Range) %>% count(Bilingual)
sum_table_race <- one_row %>% group_by(Range) %>% count(Race)
sum_table_race_simple <- one_row %>% mutate(Race = ifelse(Race == "White", "White", "nonWhite")) %>%
group_by(Range) %>% count(Race)
#sex
glm_sex <- glmer(shape_choice ~ Sex + (1|ID), data = all_data_df, family = "binomial")
Anova(glm_sex)
library(tidyverse)
library(ggplot2)
library(lme4)       #for glmer
library(ggpubr)
library(forcats)
library(emmeans)
library(bbmle)      # for ICtab()
library(car)        # for Anova()
library(readxl)
library("writexl")
library("xlsx")
library(viridis)
library(ppcor) #for partial correlation
library(lpSolve)
library(irr) #for inter-rater reliability
library(dplyr)
library(stringr)
#for the dots on the graphs
round_any <- function(x, accuracy, f=round){f(x/ accuracy) * accuracy}
all_files <- list.files("bko2 full paradigm CSVs")
first_file <- TRUE
#Adds ID code onto each trial, binds all individual csvs into one large dataframe
for(i in 1:length(all_files)){
if(grepl("b",all_files[i])){
print(all_files[i])
if(first_file){
all_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
all_data_df <- all_data_df %>% mutate(ID = substr(all_files[i],1,6))
first_file <- FALSE
}
else{
new_data_df <- read.csv(paste0("bko2 full paradigm CSVs/",all_files[i]))
new_data_df <- new_data_df %>% mutate(ID = substr(all_files[i],1,6))
all_data_df <- rbind(all_data_df,new_data_df)
}
}
}
#filter out the NAs
all_data_df <- all_data_df %>% filter(!is.na(correct))
#use unique to check that i have all the files (e.g. 64 particpants for bko2)
unique(all_data_df$ID)
left_key = "z"
right_key = "m"
age_table <- read_excel("bko2 age table.xlsx")
all_data_df <- full_join(all_data_df,age_table, by="ID")
WJ_scores <- read_excel("WJ scores.xlsx")
all_data_df <- full_join(all_data_df,WJ_scores, by="ID")
#CALCULATE CHOICE BIAS
#first create a new column shape_choice that has a 1 if they chose round, 0 if they chose spiky
all_data_df <- all_data_df %>% mutate(shape_choice = ifelse(grepl("bouba",left_image)  & response == left_key,
1,
ifelse(grepl("bouba",right_image)  & response == right_key, 1,
0)))
#write an excel file for all this with library("xlsx")
#write.xlsx(all_data_df, file = "bko2 all trials df.xlsx")
data_orth <- all_data_df %>% group_by(ID,sound,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_all_sounds <- all_data_df %>% group_by(ID,sound,stimulus) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_vowel_type <- all_data_df %>% group_by(vowel_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_congruency = all_data_df %>% group_by(congruent, ID,Range) %>%
summarise(bias = sum(correct)/n())
data_voicing = all_data_df %>% group_by(voicing, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
data_consonant = all_data_df %>% group_by(consonant_type, ID,Range) %>%
summarise(bias = sum(shape_choice)/n()-.5)
#get one row per participant with one average score (average of all trials)
data_WJ <- all_data_df %>% group_by(ID,Age,Range,WJ_score) %>%
summarise(bias = mean(correct))
ggplot(data_WJ,aes(x = WJ_score, y = bias, color = Age))+
geom_point()+
geom_smooth(se = FALSE, method = "glm")+
scale_color_viridis_b ()+
theme_light()+
ylab("Strength of bouba-kiki bias")+
xlab("Score on the Woodcock Johnson task")
#binned by range?
ggplot(data_WJ,aes(x = WJ_score, y = bias, color = Age))+
geom_point()+
geom_smooth(se = FALSE, method = "glm")+
scale_color_viridis_b()+
theme_light()+
facet_wrap("Range")
cor.test(data_WJ$WJ_score, data_WJ$bias)
#there is a significant correlation between bias and WJ score
#partial correlation?
#library(ppcor)
pcor.test(data_WJ$WJ_score,data_WJ$bias,data_WJ$Age,method="pearson")
spcor.test(data_WJ$WJ_score,data_WJ$bias,data_WJ$Age,method="pearson")
View(data_WJ)
#to see if there is an interaction between Age and WJ score? does the correlation between 2 variables change with age?
#linear regression
WJ_lm <- lm(data_WJ$bias ~ data_WJ$Age + data_WJ$WJ_score + data_WJ$Age*data_WJ$WJ_score)
summary(WJ_lm)
